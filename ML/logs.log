2024-09-16 18:55:48,432:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-16 18:55:48,432:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-16 18:55:48,432:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-16 18:55:48,432:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-16 18:58:36,302:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-16 18:58:36,303:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-16 18:58:36,303:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-16 18:58:36,303:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-16 18:58:36,979:INFO:PyCaret RegressionExperiment
2024-09-16 18:58:36,979:INFO:Logging name: reg-default-name
2024-09-16 18:58:36,979:INFO:ML Usecase: MLUsecase.REGRESSION
2024-09-16 18:58:36,979:INFO:version 3.3.2
2024-09-16 18:58:36,979:INFO:Initializing setup()
2024-09-16 18:58:36,980:INFO:self.USI: d4fa
2024-09-16 18:58:36,980:INFO:self._variable_keys: {'fold_generator', 'gpu_n_jobs_param', 'transform_target_param', 'memory', 'logging_param', 'y_train', 'log_plots_param', 'fold_shuffle_param', '_available_plots', 'y', 'html_param', 'target_param', 'USI', 'seed', 'idx', 'y_test', 'X_train', 'pipeline', 'data', 'n_jobs_param', 'exp_name_log', 'fold_groups_param', 'X', 'X_test', 'gpu_param', 'exp_id', '_ml_usecase'}
2024-09-16 18:58:36,980:INFO:Checking environment
2024-09-16 18:58:36,980:INFO:python_version: 3.11.3
2024-09-16 18:58:36,980:INFO:python_build: ('tags/v3.11.3:f3909b8', 'Apr  4 2023 23:49:59')
2024-09-16 18:58:36,980:INFO:machine: AMD64
2024-09-16 18:58:36,995:INFO:platform: Windows-10-10.0.19045-SP0
2024-09-16 18:58:36,999:INFO:Memory: svmem(total=8459001856, available=1229352960, percent=85.5, used=7229648896, free=1229352960)
2024-09-16 18:58:36,999:INFO:Physical Core: 2
2024-09-16 18:58:36,999:INFO:Logical Core: 4
2024-09-16 18:58:37,000:INFO:Checking libraries
2024-09-16 18:58:37,000:INFO:System:
2024-09-16 18:58:37,000:INFO:    python: 3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]
2024-09-16 18:58:37,000:INFO:executable: D:\grad-proj\Scripts\python.exe
2024-09-16 18:58:37,000:INFO:   machine: Windows-10-10.0.19045-SP0
2024-09-16 18:58:37,000:INFO:PyCaret required dependencies:
2024-09-16 18:58:37,094:INFO:                 pip: 22.3.1
2024-09-16 18:58:37,094:INFO:          setuptools: 65.5.0
2024-09-16 18:58:37,094:INFO:             pycaret: 3.3.2
2024-09-16 18:58:37,094:INFO:             IPython: 8.27.0
2024-09-16 18:58:37,094:INFO:          ipywidgets: 8.1.5
2024-09-16 18:58:37,095:INFO:                tqdm: 4.66.5
2024-09-16 18:58:37,095:INFO:               numpy: 1.26.4
2024-09-16 18:58:37,095:INFO:              pandas: 2.1.4
2024-09-16 18:58:37,095:INFO:              jinja2: 3.1.4
2024-09-16 18:58:37,095:INFO:               scipy: 1.11.4
2024-09-16 18:58:37,095:INFO:              joblib: 1.3.2
2024-09-16 18:58:37,095:INFO:             sklearn: 1.4.2
2024-09-16 18:58:37,095:INFO:                pyod: 2.0.2
2024-09-16 18:58:37,095:INFO:            imblearn: 0.12.3
2024-09-16 18:58:37,095:INFO:   category_encoders: 2.6.3
2024-09-16 18:58:37,095:INFO:            lightgbm: 4.5.0
2024-09-16 18:58:37,095:INFO:               numba: 0.60.0
2024-09-16 18:58:37,095:INFO:            requests: 2.32.3
2024-09-16 18:58:37,095:INFO:          matplotlib: 3.7.5
2024-09-16 18:58:37,095:INFO:          scikitplot: 0.3.7
2024-09-16 18:58:37,095:INFO:         yellowbrick: 1.5
2024-09-16 18:58:37,095:INFO:              plotly: 5.24.1
2024-09-16 18:58:37,096:INFO:    plotly-resampler: Not installed
2024-09-16 18:58:37,096:INFO:             kaleido: 0.2.1
2024-09-16 18:58:37,096:INFO:           schemdraw: 0.15
2024-09-16 18:58:37,096:INFO:         statsmodels: 0.14.3
2024-09-16 18:58:37,096:INFO:              sktime: 0.26.0
2024-09-16 18:58:37,096:INFO:               tbats: 1.1.3
2024-09-16 18:58:37,096:INFO:            pmdarima: 2.0.4
2024-09-16 18:58:37,096:INFO:              psutil: 6.0.0
2024-09-16 18:58:37,096:INFO:          markupsafe: 2.1.5
2024-09-16 18:58:37,096:INFO:             pickle5: Not installed
2024-09-16 18:58:37,096:INFO:         cloudpickle: 3.0.0
2024-09-16 18:58:37,096:INFO:         deprecation: 2.1.0
2024-09-16 18:58:37,096:INFO:              xxhash: 3.5.0
2024-09-16 18:58:37,096:INFO:           wurlitzer: Not installed
2024-09-16 18:58:37,096:INFO:PyCaret optional dependencies:
2024-09-16 18:58:37,142:INFO:                shap: Not installed
2024-09-16 18:58:37,142:INFO:           interpret: Not installed
2024-09-16 18:58:37,142:INFO:                umap: Not installed
2024-09-16 18:58:37,142:INFO:     ydata_profiling: Not installed
2024-09-16 18:58:37,142:INFO:  explainerdashboard: Not installed
2024-09-16 18:58:37,142:INFO:             autoviz: Not installed
2024-09-16 18:58:37,143:INFO:           fairlearn: Not installed
2024-09-16 18:58:37,143:INFO:          deepchecks: Not installed
2024-09-16 18:58:37,143:INFO:             xgboost: Not installed
2024-09-16 18:58:37,143:INFO:            catboost: Not installed
2024-09-16 18:58:37,143:INFO:              kmodes: Not installed
2024-09-16 18:58:37,143:INFO:             mlxtend: Not installed
2024-09-16 18:58:37,143:INFO:       statsforecast: Not installed
2024-09-16 18:58:37,143:INFO:        tune_sklearn: Not installed
2024-09-16 18:58:37,143:INFO:                 ray: Not installed
2024-09-16 18:58:37,143:INFO:            hyperopt: Not installed
2024-09-16 18:58:37,143:INFO:              optuna: Not installed
2024-09-16 18:58:37,143:INFO:               skopt: Not installed
2024-09-16 18:58:37,143:INFO:              mlflow: Not installed
2024-09-16 18:58:37,143:INFO:              gradio: Not installed
2024-09-16 18:58:37,143:INFO:             fastapi: Not installed
2024-09-16 18:58:37,143:INFO:             uvicorn: Not installed
2024-09-16 18:58:37,143:INFO:              m2cgen: Not installed
2024-09-16 18:58:37,143:INFO:           evidently: Not installed
2024-09-16 18:58:37,144:INFO:               fugue: Not installed
2024-09-16 18:58:37,144:INFO:           streamlit: Not installed
2024-09-16 18:58:37,144:INFO:             prophet: Not installed
2024-09-16 18:58:37,144:INFO:None
2024-09-16 18:58:37,144:INFO:Set up data.
2024-09-16 18:58:37,182:INFO:Set up folding strategy.
2024-09-16 18:58:37,183:INFO:Set up train/test split.
2024-09-16 18:58:37,222:INFO:Set up index.
2024-09-16 18:58:37,222:INFO:Assigning column types.
2024-09-16 18:58:37,227:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-16 18:58:37,228:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-09-16 18:58:37,235:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-09-16 18:58:37,240:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-09-16 18:58:37,317:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 18:58:37,372:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-16 18:58:37,372:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 18:58:37,373:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 18:58:37,373:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-09-16 18:58:37,379:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-09-16 18:58:37,384:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-09-16 18:58:37,463:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 18:58:37,520:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-16 18:58:37,520:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 18:58:37,521:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 18:58:37,521:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-09-16 18:58:37,526:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-09-16 18:58:37,532:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-09-16 18:58:37,606:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 18:58:37,662:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-16 18:58:37,663:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 18:58:37,663:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 18:58:37,669:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-09-16 18:58:37,677:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-09-16 18:58:37,757:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 18:58:37,812:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-16 18:58:37,813:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 18:58:37,813:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 18:58:37,814:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-09-16 18:58:37,827:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-09-16 18:58:37,911:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 18:58:37,967:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-16 18:58:37,968:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 18:58:37,968:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 18:58:37,980:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-09-16 18:58:38,058:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 18:58:38,111:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-16 18:58:38,112:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 18:58:38,112:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 18:58:38,113:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-09-16 18:58:38,202:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 18:58:38,258:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-16 18:58:38,259:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 18:58:38,260:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 18:58:38,344:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 18:58:38,398:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-16 18:58:38,399:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 18:58:38,399:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 18:58:38,400:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-16 18:58:38,486:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 18:58:38,542:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 18:58:38,542:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 18:58:38,633:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 18:58:38,815:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 18:58:38,816:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 18:58:38,818:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-09-16 18:58:38,984:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 18:58:38,984:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 18:58:39,140:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 18:58:39,141:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 18:58:39,146:INFO:Preparing preprocessing pipeline...
2024-09-16 18:58:39,146:INFO:Set up simple imputation.
2024-09-16 18:58:39,151:INFO:Set up encoding of categorical features.
2024-09-16 18:58:39,659:INFO:Finished creating preprocessing pipeline.
2024-09-16 18:58:39,680:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Dell\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['long', 'lat', 'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['city', 'neighborhood',
                                             'subcategory', 'facade',
                                             'payment_method', 'bedrooms',
                                             'bathrooms', 'furnished', 'floor',
                                             'building_...
                                             'bathrooms', 'furnished', 'floor',
                                             'building_age'],
                                    transformer=OneHotEncoder(cols=['city',
                                                                    'subcategory',
                                                                    'facade',
                                                                    'payment_method',
                                                                    'bedrooms',
                                                                    'bathrooms',
                                                                    'furnished',
                                                                    'floor',
                                                                    'building_age'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['neighborhood'],
                                    transformer=TargetEncoder(cols=['neighborhood'],
                                                              handle_missing='return_nan')))])
2024-09-16 18:58:39,680:INFO:Creating final display dataframe.
2024-09-16 18:58:40,536:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             price
2                   Target type        Regression
3           Original data shape        (8513, 14)
4        Transformed data shape        (8513, 96)
5   Transformed train set shape        (5959, 96)
6    Transformed test set shape        (2554, 96)
7              Numeric features                 3
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              d4fa
2024-09-16 18:58:40,689:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 18:58:40,689:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 18:58:40,830:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 18:58:40,830:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 18:58:40,831:INFO:setup() successfully completed in 3.86s...............
2024-09-16 18:58:40,831:INFO:Initializing compare_models()
2024-09-16 18:58:40,831:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000114FDB21210>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000114FDB21210>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2024-09-16 18:58:40,831:INFO:Checking exceptions
2024-09-16 18:58:40,834:INFO:Preparing display monitor
2024-09-16 18:58:40,839:INFO:Initializing Linear Regression
2024-09-16 18:58:40,840:INFO:Total runtime is 1.69674555460612e-05 minutes
2024-09-16 18:58:40,840:INFO:SubProcess create_model() called ==================================
2024-09-16 18:58:40,840:INFO:Initializing create_model()
2024-09-16 18:58:40,840:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000114FDB21210>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000114FE16BAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 18:58:40,840:INFO:Checking exceptions
2024-09-16 18:58:40,840:INFO:Importing libraries
2024-09-16 18:58:40,840:INFO:Copying training dataset
2024-09-16 18:58:40,848:INFO:Defining folds
2024-09-16 18:58:40,848:INFO:Declaring metric variables
2024-09-16 18:58:40,848:INFO:Importing untrained model
2024-09-16 18:58:40,848:INFO:Linear Regression Imported successfully
2024-09-16 18:58:40,849:INFO:Starting cross validation
2024-09-16 18:58:40,862:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 18:58:56,247:INFO:Calculating mean and std
2024-09-16 18:58:56,260:INFO:Creating metrics dataframe
2024-09-16 18:58:56,264:INFO:Uploading results into container
2024-09-16 18:58:56,265:INFO:Uploading model into container now
2024-09-16 18:58:56,265:INFO:_master_model_container: 1
2024-09-16 18:58:56,266:INFO:_display_container: 2
2024-09-16 18:58:56,266:INFO:LinearRegression(n_jobs=-1)
2024-09-16 18:58:56,266:INFO:create_model() successfully completed......................................
2024-09-16 18:58:56,364:INFO:SubProcess create_model() end ==================================
2024-09-16 18:58:56,364:INFO:Creating metrics dataframe
2024-09-16 18:58:56,370:INFO:Initializing Lasso Regression
2024-09-16 18:58:56,371:INFO:Total runtime is 0.25887919664382936 minutes
2024-09-16 18:58:56,371:INFO:SubProcess create_model() called ==================================
2024-09-16 18:58:56,372:INFO:Initializing create_model()
2024-09-16 18:58:56,372:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000114FDB21210>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000114FE16BAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 18:58:56,372:INFO:Checking exceptions
2024-09-16 18:58:56,372:INFO:Importing libraries
2024-09-16 18:58:56,372:INFO:Copying training dataset
2024-09-16 18:58:56,385:INFO:Defining folds
2024-09-16 18:58:56,385:INFO:Declaring metric variables
2024-09-16 18:58:56,385:INFO:Importing untrained model
2024-09-16 18:58:56,386:INFO:Lasso Regression Imported successfully
2024-09-16 18:58:56,386:INFO:Starting cross validation
2024-09-16 18:58:56,393:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 18:58:59,393:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.137e+14, tolerance: 1.323e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 18:58:59,446:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.201e+14, tolerance: 1.340e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 18:58:59,477:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.188e+14, tolerance: 1.331e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 18:58:59,529:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.294e+14, tolerance: 1.117e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 18:59:02,196:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.255e+14, tolerance: 1.343e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 18:59:02,620:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.306e+14, tolerance: 9.170e+10
  model = cd_fast.enet_coordinate_descent(

2024-09-16 18:59:02,683:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.939e+14, tolerance: 1.272e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 18:59:02,713:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.035e+14, tolerance: 1.303e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 18:59:04,493:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.022e+14, tolerance: 1.288e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 18:59:04,742:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.888e+14, tolerance: 1.268e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 18:59:04,868:INFO:Calculating mean and std
2024-09-16 18:59:04,870:INFO:Creating metrics dataframe
2024-09-16 18:59:04,873:INFO:Uploading results into container
2024-09-16 18:59:04,873:INFO:Uploading model into container now
2024-09-16 18:59:04,874:INFO:_master_model_container: 2
2024-09-16 18:59:04,874:INFO:_display_container: 2
2024-09-16 18:59:04,874:INFO:Lasso(random_state=123)
2024-09-16 18:59:04,874:INFO:create_model() successfully completed......................................
2024-09-16 18:59:04,966:INFO:SubProcess create_model() end ==================================
2024-09-16 18:59:04,966:INFO:Creating metrics dataframe
2024-09-16 18:59:04,972:INFO:Initializing Ridge Regression
2024-09-16 18:59:04,972:INFO:Total runtime is 0.4022239883740743 minutes
2024-09-16 18:59:04,973:INFO:SubProcess create_model() called ==================================
2024-09-16 18:59:04,973:INFO:Initializing create_model()
2024-09-16 18:59:04,973:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000114FDB21210>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000114FE16BAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 18:59:04,973:INFO:Checking exceptions
2024-09-16 18:59:04,973:INFO:Importing libraries
2024-09-16 18:59:04,973:INFO:Copying training dataset
2024-09-16 18:59:04,982:INFO:Defining folds
2024-09-16 18:59:04,982:INFO:Declaring metric variables
2024-09-16 18:59:04,983:INFO:Importing untrained model
2024-09-16 18:59:04,983:INFO:Ridge Regression Imported successfully
2024-09-16 18:59:04,984:INFO:Starting cross validation
2024-09-16 18:59:04,989:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 18:59:05,722:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.1653e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 18:59:05,727:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.31329e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 18:59:05,743:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.16211e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 18:59:06,616:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.15281e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 18:59:06,650:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.14216e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 18:59:06,665:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.16155e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 18:59:06,701:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.1704e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 18:59:07,381:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.16172e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 18:59:07,400:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.16082e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 18:59:07,513:INFO:Calculating mean and std
2024-09-16 18:59:07,514:INFO:Creating metrics dataframe
2024-09-16 18:59:07,516:INFO:Uploading results into container
2024-09-16 18:59:07,517:INFO:Uploading model into container now
2024-09-16 18:59:07,518:INFO:_master_model_container: 3
2024-09-16 18:59:07,518:INFO:_display_container: 2
2024-09-16 18:59:07,518:INFO:Ridge(random_state=123)
2024-09-16 18:59:07,518:INFO:create_model() successfully completed......................................
2024-09-16 18:59:07,606:INFO:SubProcess create_model() end ==================================
2024-09-16 18:59:07,606:INFO:Creating metrics dataframe
2024-09-16 18:59:07,610:INFO:Initializing Elastic Net
2024-09-16 18:59:07,610:INFO:Total runtime is 0.4461941162745158 minutes
2024-09-16 18:59:07,610:INFO:SubProcess create_model() called ==================================
2024-09-16 18:59:07,610:INFO:Initializing create_model()
2024-09-16 18:59:07,610:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000114FDB21210>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000114FE16BAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 18:59:07,610:INFO:Checking exceptions
2024-09-16 18:59:07,611:INFO:Importing libraries
2024-09-16 18:59:07,611:INFO:Copying training dataset
2024-09-16 18:59:07,619:INFO:Defining folds
2024-09-16 18:59:07,619:INFO:Declaring metric variables
2024-09-16 18:59:07,619:INFO:Importing untrained model
2024-09-16 18:59:07,620:INFO:Elastic Net Imported successfully
2024-09-16 18:59:07,621:INFO:Starting cross validation
2024-09-16 18:59:07,626:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 18:59:10,334:INFO:Calculating mean and std
2024-09-16 18:59:10,335:INFO:Creating metrics dataframe
2024-09-16 18:59:10,338:INFO:Uploading results into container
2024-09-16 18:59:10,339:INFO:Uploading model into container now
2024-09-16 18:59:10,339:INFO:_master_model_container: 4
2024-09-16 18:59:10,339:INFO:_display_container: 2
2024-09-16 18:59:10,340:INFO:ElasticNet(random_state=123)
2024-09-16 18:59:10,340:INFO:create_model() successfully completed......................................
2024-09-16 18:59:10,427:INFO:SubProcess create_model() end ==================================
2024-09-16 18:59:10,427:INFO:Creating metrics dataframe
2024-09-16 18:59:10,432:INFO:Initializing Least Angle Regression
2024-09-16 18:59:10,432:INFO:Total runtime is 0.4932268063227335 minutes
2024-09-16 18:59:10,432:INFO:SubProcess create_model() called ==================================
2024-09-16 18:59:10,432:INFO:Initializing create_model()
2024-09-16 18:59:10,432:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000114FDB21210>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000114FE16BAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 18:59:10,432:INFO:Checking exceptions
2024-09-16 18:59:10,433:INFO:Importing libraries
2024-09-16 18:59:10,433:INFO:Copying training dataset
2024-09-16 18:59:10,441:INFO:Defining folds
2024-09-16 18:59:10,442:INFO:Declaring metric variables
2024-09-16 18:59:10,442:INFO:Importing untrained model
2024-09-16 18:59:10,443:INFO:Least Angle Regression Imported successfully
2024-09-16 18:59:10,443:INFO:Starting cross validation
2024-09-16 18:59:10,448:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 18:59:11,276:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=5.117e+02, with an active set of 48 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,277:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=6.766e+02, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,283:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=7.507e+02, with an active set of 51 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,285:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=1.119e+03, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,286:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=7.398e+02, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,288:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=6.903e+02, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,291:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=4.506e+02, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,294:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=7.938e+02, with an active set of 60 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,295:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=7.735e+02, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,297:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=4.405e+04, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,300:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=6.115e+02, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,301:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=7.454e+02, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,305:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=2.817e+04, with an active set of 91 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,307:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=4.569e+04, with an active set of 93 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,310:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=5.678e+03, with an active set of 77 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,311:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=5.551e+03, with an active set of 78 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,311:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=2.705e+03, with an active set of 91 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,313:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=1.709e+03, with an active set of 93 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,313:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=1.009e+03, with an active set of 93 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,314:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 82 iterations, i.e. alpha=5.650e+02, with an active set of 69 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,322:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=8.438e+02, with an active set of 81 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,323:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=6.889e+02, with an active set of 81 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,324:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=6.362e+02, with an active set of 83 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,325:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=5.884e+02, with an active set of 84 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,326:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=4.347e+02, with an active set of 85 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,326:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=3.550e+02, with an active set of 85 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,327:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=2.184e+02, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,328:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=1.207e+02, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,328:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=4.657e+01, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,329:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=2.065e+01, with an active set of 87 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,331:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=1.377e+01, with an active set of 89 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,331:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=9.817e+00, with an active set of 89 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,332:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=6.965e+00, with an active set of 90 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,333:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=6.700e+00, with an active set of 90 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:11,333:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=2.479e+00, with an active set of 90 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:12,236:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=9.048e+02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:12,241:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.101e+03, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:12,277:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=5.990e+02, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:12,295:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=9.455e+02, with an active set of 44 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:12,301:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=1.805e+09, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:12,304:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=1.419e+09, with an active set of 91 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:12,306:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=4.235e+08, with an active set of 93 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:12,976:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=7.038e+03, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:13,089:INFO:Calculating mean and std
2024-09-16 18:59:13,090:INFO:Creating metrics dataframe
2024-09-16 18:59:13,093:INFO:Uploading results into container
2024-09-16 18:59:13,094:INFO:Uploading model into container now
2024-09-16 18:59:13,095:INFO:_master_model_container: 5
2024-09-16 18:59:13,095:INFO:_display_container: 2
2024-09-16 18:59:13,095:INFO:Lars(random_state=123)
2024-09-16 18:59:13,095:INFO:create_model() successfully completed......................................
2024-09-16 18:59:13,194:INFO:SubProcess create_model() end ==================================
2024-09-16 18:59:13,194:INFO:Creating metrics dataframe
2024-09-16 18:59:13,200:INFO:Initializing Lasso Least Angle Regression
2024-09-16 18:59:13,200:INFO:Total runtime is 0.5393654465675354 minutes
2024-09-16 18:59:13,201:INFO:SubProcess create_model() called ==================================
2024-09-16 18:59:13,201:INFO:Initializing create_model()
2024-09-16 18:59:13,201:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000114FDB21210>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000114FE16BAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 18:59:13,201:INFO:Checking exceptions
2024-09-16 18:59:13,202:INFO:Importing libraries
2024-09-16 18:59:13,202:INFO:Copying training dataset
2024-09-16 18:59:13,211:INFO:Defining folds
2024-09-16 18:59:13,211:INFO:Declaring metric variables
2024-09-16 18:59:13,212:INFO:Importing untrained model
2024-09-16 18:59:13,213:INFO:Lasso Least Angle Regression Imported successfully
2024-09-16 18:59:13,213:INFO:Starting cross validation
2024-09-16 18:59:13,220:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 18:59:13,917:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=3.070e+01, with an active set of 75 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:13,924:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 98 iterations, alpha=1.535e+01, previous alpha=1.535e+01, with an active set of 81 regressors.
  warnings.warn(

2024-09-16 18:59:13,972:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=1.435e+02, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:13,973:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=1.180e+02, with an active set of 60 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:13,978:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 82 iterations, alpha=9.372e+01, previous alpha=7.755e+01, with an active set of 73 regressors.
  warnings.warn(

2024-09-16 18:59:14,006:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 108 iterations, alpha=2.212e+00, previous alpha=2.212e+00, with an active set of 81 regressors.
  warnings.warn(

2024-09-16 18:59:14,866:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 102 iterations, alpha=9.960e+00, previous alpha=5.387e+00, with an active set of 79 regressors.
  warnings.warn(

2024-09-16 18:59:14,921:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=1.548e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:14,923:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=1.044e+01, with an active set of 77 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:14,929:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 108 iterations, alpha=5.444e+00, previous alpha=5.444e+00, with an active set of 79 regressors.
  warnings.warn(

2024-09-16 18:59:14,971:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=2.452e+01, with an active set of 75 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:14,976:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 101 iterations, alpha=1.817e+01, previous alpha=1.817e+01, with an active set of 76 regressors.
  warnings.warn(

2024-09-16 18:59:15,566:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=2.071e+02, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:15,567:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=1.952e+02, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:15,569:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=1.306e+02, with an active set of 61 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 18:59:15,570:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 68 iterations, alpha=1.363e+02, previous alpha=1.306e+02, with an active set of 61 regressors.
  warnings.warn(

2024-09-16 18:59:15,603:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 99 iterations, alpha=2.537e+01, previous alpha=2.533e+01, with an active set of 78 regressors.
  warnings.warn(

2024-09-16 18:59:15,706:INFO:Calculating mean and std
2024-09-16 18:59:15,707:INFO:Creating metrics dataframe
2024-09-16 18:59:15,710:INFO:Uploading results into container
2024-09-16 18:59:15,711:INFO:Uploading model into container now
2024-09-16 18:59:15,712:INFO:_master_model_container: 6
2024-09-16 18:59:15,712:INFO:_display_container: 2
2024-09-16 18:59:15,713:INFO:LassoLars(random_state=123)
2024-09-16 18:59:15,713:INFO:create_model() successfully completed......................................
2024-09-16 18:59:15,804:INFO:SubProcess create_model() end ==================================
2024-09-16 18:59:15,804:INFO:Creating metrics dataframe
2024-09-16 18:59:15,809:INFO:Initializing Orthogonal Matching Pursuit
2024-09-16 18:59:15,809:INFO:Total runtime is 0.5828420162200928 minutes
2024-09-16 18:59:15,809:INFO:SubProcess create_model() called ==================================
2024-09-16 18:59:15,810:INFO:Initializing create_model()
2024-09-16 18:59:15,810:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000114FDB21210>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000114FE16BAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 18:59:15,810:INFO:Checking exceptions
2024-09-16 18:59:15,810:INFO:Importing libraries
2024-09-16 18:59:15,810:INFO:Copying training dataset
2024-09-16 18:59:15,818:INFO:Defining folds
2024-09-16 18:59:15,818:INFO:Declaring metric variables
2024-09-16 18:59:15,819:INFO:Importing untrained model
2024-09-16 18:59:15,819:INFO:Orthogonal Matching Pursuit Imported successfully
2024-09-16 18:59:15,819:INFO:Starting cross validation
2024-09-16 18:59:15,824:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 18:59:18,123:INFO:Calculating mean and std
2024-09-16 18:59:18,124:INFO:Creating metrics dataframe
2024-09-16 18:59:18,126:INFO:Uploading results into container
2024-09-16 18:59:18,127:INFO:Uploading model into container now
2024-09-16 18:59:18,128:INFO:_master_model_container: 7
2024-09-16 18:59:18,128:INFO:_display_container: 2
2024-09-16 18:59:18,128:INFO:OrthogonalMatchingPursuit()
2024-09-16 18:59:18,128:INFO:create_model() successfully completed......................................
2024-09-16 18:59:18,210:INFO:SubProcess create_model() end ==================================
2024-09-16 18:59:18,210:INFO:Creating metrics dataframe
2024-09-16 18:59:18,214:INFO:Initializing Bayesian Ridge
2024-09-16 18:59:18,214:INFO:Total runtime is 0.6229226152102153 minutes
2024-09-16 18:59:18,214:INFO:SubProcess create_model() called ==================================
2024-09-16 18:59:18,214:INFO:Initializing create_model()
2024-09-16 18:59:18,214:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000114FDB21210>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000114FE16BAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 18:59:18,214:INFO:Checking exceptions
2024-09-16 18:59:18,214:INFO:Importing libraries
2024-09-16 18:59:18,214:INFO:Copying training dataset
2024-09-16 18:59:18,221:INFO:Defining folds
2024-09-16 18:59:18,222:INFO:Declaring metric variables
2024-09-16 18:59:18,222:INFO:Importing untrained model
2024-09-16 18:59:18,222:INFO:Bayesian Ridge Imported successfully
2024-09-16 18:59:18,222:INFO:Starting cross validation
2024-09-16 18:59:18,226:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 18:59:21,030:INFO:Calculating mean and std
2024-09-16 18:59:21,031:INFO:Creating metrics dataframe
2024-09-16 18:59:21,034:INFO:Uploading results into container
2024-09-16 18:59:21,034:INFO:Uploading model into container now
2024-09-16 18:59:21,035:INFO:_master_model_container: 8
2024-09-16 18:59:21,035:INFO:_display_container: 2
2024-09-16 18:59:21,035:INFO:BayesianRidge()
2024-09-16 18:59:21,035:INFO:create_model() successfully completed......................................
2024-09-16 18:59:21,118:INFO:SubProcess create_model() end ==================================
2024-09-16 18:59:21,118:INFO:Creating metrics dataframe
2024-09-16 18:59:21,121:INFO:Initializing Passive Aggressive Regressor
2024-09-16 18:59:21,121:INFO:Total runtime is 0.6713683366775514 minutes
2024-09-16 18:59:21,122:INFO:SubProcess create_model() called ==================================
2024-09-16 18:59:21,122:INFO:Initializing create_model()
2024-09-16 18:59:21,122:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000114FDB21210>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000114FE16BAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 18:59:21,122:INFO:Checking exceptions
2024-09-16 18:59:21,122:INFO:Importing libraries
2024-09-16 18:59:21,122:INFO:Copying training dataset
2024-09-16 18:59:21,130:INFO:Defining folds
2024-09-16 18:59:21,130:INFO:Declaring metric variables
2024-09-16 18:59:21,130:INFO:Importing untrained model
2024-09-16 18:59:21,130:INFO:Passive Aggressive Regressor Imported successfully
2024-09-16 18:59:21,131:INFO:Starting cross validation
2024-09-16 18:59:21,134:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 18:59:23,651:INFO:Calculating mean and std
2024-09-16 18:59:23,652:INFO:Creating metrics dataframe
2024-09-16 18:59:23,654:INFO:Uploading results into container
2024-09-16 18:59:23,655:INFO:Uploading model into container now
2024-09-16 18:59:23,655:INFO:_master_model_container: 9
2024-09-16 18:59:23,655:INFO:_display_container: 2
2024-09-16 18:59:23,656:INFO:PassiveAggressiveRegressor(random_state=123)
2024-09-16 18:59:23,656:INFO:create_model() successfully completed......................................
2024-09-16 18:59:23,739:INFO:SubProcess create_model() end ==================================
2024-09-16 18:59:23,739:INFO:Creating metrics dataframe
2024-09-16 18:59:23,742:INFO:Initializing Huber Regressor
2024-09-16 18:59:23,742:INFO:Total runtime is 0.7150650103886923 minutes
2024-09-16 18:59:23,742:INFO:SubProcess create_model() called ==================================
2024-09-16 18:59:23,743:INFO:Initializing create_model()
2024-09-16 18:59:23,743:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000114FDB21210>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000114FE16BAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 18:59:23,743:INFO:Checking exceptions
2024-09-16 18:59:23,743:INFO:Importing libraries
2024-09-16 18:59:23,743:INFO:Copying training dataset
2024-09-16 18:59:23,750:INFO:Defining folds
2024-09-16 18:59:23,750:INFO:Declaring metric variables
2024-09-16 18:59:23,750:INFO:Importing untrained model
2024-09-16 18:59:23,751:INFO:Huber Regressor Imported successfully
2024-09-16 18:59:23,751:INFO:Starting cross validation
2024-09-16 18:59:23,754:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 18:59:27,042:INFO:Calculating mean and std
2024-09-16 18:59:27,043:INFO:Creating metrics dataframe
2024-09-16 18:59:27,045:INFO:Uploading results into container
2024-09-16 18:59:27,046:INFO:Uploading model into container now
2024-09-16 18:59:27,047:INFO:_master_model_container: 10
2024-09-16 18:59:27,047:INFO:_display_container: 2
2024-09-16 18:59:27,047:INFO:HuberRegressor()
2024-09-16 18:59:27,047:INFO:create_model() successfully completed......................................
2024-09-16 18:59:27,130:INFO:SubProcess create_model() end ==================================
2024-09-16 18:59:27,130:INFO:Creating metrics dataframe
2024-09-16 18:59:27,133:INFO:Initializing K Neighbors Regressor
2024-09-16 18:59:27,133:INFO:Total runtime is 0.7715688943862916 minutes
2024-09-16 18:59:27,133:INFO:SubProcess create_model() called ==================================
2024-09-16 18:59:27,133:INFO:Initializing create_model()
2024-09-16 18:59:27,133:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000114FDB21210>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000114FE16BAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 18:59:27,134:INFO:Checking exceptions
2024-09-16 18:59:27,134:INFO:Importing libraries
2024-09-16 18:59:27,134:INFO:Copying training dataset
2024-09-16 18:59:27,141:INFO:Defining folds
2024-09-16 18:59:27,141:INFO:Declaring metric variables
2024-09-16 18:59:27,141:INFO:Importing untrained model
2024-09-16 18:59:27,141:INFO:K Neighbors Regressor Imported successfully
2024-09-16 18:59:27,142:INFO:Starting cross validation
2024-09-16 18:59:27,146:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 18:59:30,047:INFO:Calculating mean and std
2024-09-16 18:59:30,048:INFO:Creating metrics dataframe
2024-09-16 18:59:30,051:INFO:Uploading results into container
2024-09-16 18:59:30,051:INFO:Uploading model into container now
2024-09-16 18:59:30,052:INFO:_master_model_container: 11
2024-09-16 18:59:30,052:INFO:_display_container: 2
2024-09-16 18:59:30,052:INFO:KNeighborsRegressor(n_jobs=-1)
2024-09-16 18:59:30,052:INFO:create_model() successfully completed......................................
2024-09-16 18:59:30,135:INFO:SubProcess create_model() end ==================================
2024-09-16 18:59:30,136:INFO:Creating metrics dataframe
2024-09-16 18:59:30,139:INFO:Initializing Decision Tree Regressor
2024-09-16 18:59:30,139:INFO:Total runtime is 0.8216790040334067 minutes
2024-09-16 18:59:30,139:INFO:SubProcess create_model() called ==================================
2024-09-16 18:59:30,139:INFO:Initializing create_model()
2024-09-16 18:59:30,139:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000114FDB21210>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000114FE16BAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 18:59:30,140:INFO:Checking exceptions
2024-09-16 18:59:30,140:INFO:Importing libraries
2024-09-16 18:59:30,140:INFO:Copying training dataset
2024-09-16 18:59:30,147:INFO:Defining folds
2024-09-16 18:59:30,147:INFO:Declaring metric variables
2024-09-16 18:59:30,147:INFO:Importing untrained model
2024-09-16 18:59:30,148:INFO:Decision Tree Regressor Imported successfully
2024-09-16 18:59:30,149:INFO:Starting cross validation
2024-09-16 18:59:30,153:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 18:59:32,674:INFO:Calculating mean and std
2024-09-16 18:59:32,675:INFO:Creating metrics dataframe
2024-09-16 18:59:32,677:INFO:Uploading results into container
2024-09-16 18:59:32,678:INFO:Uploading model into container now
2024-09-16 18:59:32,678:INFO:_master_model_container: 12
2024-09-16 18:59:32,679:INFO:_display_container: 2
2024-09-16 18:59:32,679:INFO:DecisionTreeRegressor(random_state=123)
2024-09-16 18:59:32,679:INFO:create_model() successfully completed......................................
2024-09-16 18:59:32,761:INFO:SubProcess create_model() end ==================================
2024-09-16 18:59:32,761:INFO:Creating metrics dataframe
2024-09-16 18:59:32,764:INFO:Initializing Random Forest Regressor
2024-09-16 18:59:32,764:INFO:Total runtime is 0.8654268741607667 minutes
2024-09-16 18:59:32,765:INFO:SubProcess create_model() called ==================================
2024-09-16 18:59:32,765:INFO:Initializing create_model()
2024-09-16 18:59:32,765:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000114FDB21210>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000114FE16BAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 18:59:32,765:INFO:Checking exceptions
2024-09-16 18:59:32,765:INFO:Importing libraries
2024-09-16 18:59:32,765:INFO:Copying training dataset
2024-09-16 18:59:32,772:INFO:Defining folds
2024-09-16 18:59:32,773:INFO:Declaring metric variables
2024-09-16 18:59:32,773:INFO:Importing untrained model
2024-09-16 18:59:32,773:INFO:Random Forest Regressor Imported successfully
2024-09-16 18:59:32,774:INFO:Starting cross validation
2024-09-16 18:59:32,777:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:00:06,243:INFO:Calculating mean and std
2024-09-16 19:00:06,245:INFO:Creating metrics dataframe
2024-09-16 19:00:06,247:INFO:Uploading results into container
2024-09-16 19:00:06,248:INFO:Uploading model into container now
2024-09-16 19:00:06,248:INFO:_master_model_container: 13
2024-09-16 19:00:06,248:INFO:_display_container: 2
2024-09-16 19:00:06,249:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-09-16 19:00:06,249:INFO:create_model() successfully completed......................................
2024-09-16 19:00:06,353:INFO:SubProcess create_model() end ==================================
2024-09-16 19:00:06,353:INFO:Creating metrics dataframe
2024-09-16 19:00:06,358:INFO:Initializing Extra Trees Regressor
2024-09-16 19:00:06,359:INFO:Total runtime is 1.425321622689565 minutes
2024-09-16 19:00:06,359:INFO:SubProcess create_model() called ==================================
2024-09-16 19:00:06,360:INFO:Initializing create_model()
2024-09-16 19:00:06,360:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000114FDB21210>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000114FE16BAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:00:06,360:INFO:Checking exceptions
2024-09-16 19:00:06,360:INFO:Importing libraries
2024-09-16 19:00:06,360:INFO:Copying training dataset
2024-09-16 19:00:06,377:INFO:Defining folds
2024-09-16 19:00:06,377:INFO:Declaring metric variables
2024-09-16 19:00:06,378:INFO:Importing untrained model
2024-09-16 19:00:06,379:INFO:Extra Trees Regressor Imported successfully
2024-09-16 19:00:06,379:INFO:Starting cross validation
2024-09-16 19:00:06,388:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:00:40,082:INFO:Calculating mean and std
2024-09-16 19:00:40,084:INFO:Creating metrics dataframe
2024-09-16 19:00:40,087:INFO:Uploading results into container
2024-09-16 19:00:40,088:INFO:Uploading model into container now
2024-09-16 19:00:40,088:INFO:_master_model_container: 14
2024-09-16 19:00:40,088:INFO:_display_container: 2
2024-09-16 19:00:40,089:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-09-16 19:00:40,089:INFO:create_model() successfully completed......................................
2024-09-16 19:00:40,177:INFO:SubProcess create_model() end ==================================
2024-09-16 19:00:40,178:INFO:Creating metrics dataframe
2024-09-16 19:00:40,181:INFO:Initializing AdaBoost Regressor
2024-09-16 19:00:40,181:INFO:Total runtime is 1.9890355706214904 minutes
2024-09-16 19:00:40,181:INFO:SubProcess create_model() called ==================================
2024-09-16 19:00:40,182:INFO:Initializing create_model()
2024-09-16 19:00:40,182:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000114FDB21210>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000114FE16BAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:00:40,182:INFO:Checking exceptions
2024-09-16 19:00:40,182:INFO:Importing libraries
2024-09-16 19:00:40,182:INFO:Copying training dataset
2024-09-16 19:00:40,190:INFO:Defining folds
2024-09-16 19:00:40,190:INFO:Declaring metric variables
2024-09-16 19:00:40,191:INFO:Importing untrained model
2024-09-16 19:00:40,191:INFO:AdaBoost Regressor Imported successfully
2024-09-16 19:00:40,192:INFO:Starting cross validation
2024-09-16 19:00:40,195:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:00:48,717:INFO:Calculating mean and std
2024-09-16 19:00:48,718:INFO:Creating metrics dataframe
2024-09-16 19:00:48,721:INFO:Uploading results into container
2024-09-16 19:00:48,722:INFO:Uploading model into container now
2024-09-16 19:00:48,723:INFO:_master_model_container: 15
2024-09-16 19:00:48,723:INFO:_display_container: 2
2024-09-16 19:00:48,723:INFO:AdaBoostRegressor(random_state=123)
2024-09-16 19:00:48,723:INFO:create_model() successfully completed......................................
2024-09-16 19:00:48,822:INFO:SubProcess create_model() end ==================================
2024-09-16 19:00:48,823:INFO:Creating metrics dataframe
2024-09-16 19:00:48,828:INFO:Initializing Gradient Boosting Regressor
2024-09-16 19:00:48,828:INFO:Total runtime is 2.133154507478078 minutes
2024-09-16 19:00:48,829:INFO:SubProcess create_model() called ==================================
2024-09-16 19:00:48,829:INFO:Initializing create_model()
2024-09-16 19:00:48,829:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000114FDB21210>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000114FE16BAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:00:48,829:INFO:Checking exceptions
2024-09-16 19:00:48,829:INFO:Importing libraries
2024-09-16 19:00:48,830:INFO:Copying training dataset
2024-09-16 19:00:48,843:INFO:Defining folds
2024-09-16 19:00:48,843:INFO:Declaring metric variables
2024-09-16 19:00:48,843:INFO:Importing untrained model
2024-09-16 19:00:48,845:INFO:Gradient Boosting Regressor Imported successfully
2024-09-16 19:00:48,845:INFO:Starting cross validation
2024-09-16 19:00:48,853:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:00:58,584:INFO:Calculating mean and std
2024-09-16 19:00:58,585:INFO:Creating metrics dataframe
2024-09-16 19:00:58,587:INFO:Uploading results into container
2024-09-16 19:00:58,588:INFO:Uploading model into container now
2024-09-16 19:00:58,588:INFO:_master_model_container: 16
2024-09-16 19:00:58,588:INFO:_display_container: 2
2024-09-16 19:00:58,589:INFO:GradientBoostingRegressor(random_state=123)
2024-09-16 19:00:58,589:INFO:create_model() successfully completed......................................
2024-09-16 19:00:58,671:INFO:SubProcess create_model() end ==================================
2024-09-16 19:00:58,671:INFO:Creating metrics dataframe
2024-09-16 19:00:58,674:INFO:Initializing Light Gradient Boosting Machine
2024-09-16 19:00:58,675:INFO:Total runtime is 2.2972755352656042 minutes
2024-09-16 19:00:58,675:INFO:SubProcess create_model() called ==================================
2024-09-16 19:00:58,675:INFO:Initializing create_model()
2024-09-16 19:00:58,675:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000114FDB21210>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000114FE16BAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:00:58,675:INFO:Checking exceptions
2024-09-16 19:00:58,675:INFO:Importing libraries
2024-09-16 19:00:58,675:INFO:Copying training dataset
2024-09-16 19:00:58,682:INFO:Defining folds
2024-09-16 19:00:58,682:INFO:Declaring metric variables
2024-09-16 19:00:58,682:INFO:Importing untrained model
2024-09-16 19:00:58,683:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-16 19:00:58,683:INFO:Starting cross validation
2024-09-16 19:00:58,687:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:01:02,667:INFO:Calculating mean and std
2024-09-16 19:01:02,669:INFO:Creating metrics dataframe
2024-09-16 19:01:02,672:INFO:Uploading results into container
2024-09-16 19:01:02,673:INFO:Uploading model into container now
2024-09-16 19:01:02,673:INFO:_master_model_container: 17
2024-09-16 19:01:02,674:INFO:_display_container: 2
2024-09-16 19:01:02,674:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-09-16 19:01:02,675:INFO:create_model() successfully completed......................................
2024-09-16 19:01:02,791:INFO:SubProcess create_model() end ==================================
2024-09-16 19:01:02,791:INFO:Creating metrics dataframe
2024-09-16 19:01:02,797:INFO:Initializing Dummy Regressor
2024-09-16 19:01:02,797:INFO:Total runtime is 2.3659744977951047 minutes
2024-09-16 19:01:02,797:INFO:SubProcess create_model() called ==================================
2024-09-16 19:01:02,798:INFO:Initializing create_model()
2024-09-16 19:01:02,798:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000114FDB21210>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000114FE16BAD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:01:02,798:INFO:Checking exceptions
2024-09-16 19:01:02,798:INFO:Importing libraries
2024-09-16 19:01:02,798:INFO:Copying training dataset
2024-09-16 19:01:02,815:INFO:Defining folds
2024-09-16 19:01:02,815:INFO:Declaring metric variables
2024-09-16 19:01:02,816:INFO:Importing untrained model
2024-09-16 19:01:02,817:INFO:Dummy Regressor Imported successfully
2024-09-16 19:01:02,818:INFO:Starting cross validation
2024-09-16 19:01:02,831:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:01:05,118:INFO:Calculating mean and std
2024-09-16 19:01:05,119:INFO:Creating metrics dataframe
2024-09-16 19:01:05,122:INFO:Uploading results into container
2024-09-16 19:01:05,123:INFO:Uploading model into container now
2024-09-16 19:01:05,124:INFO:_master_model_container: 18
2024-09-16 19:01:05,124:INFO:_display_container: 2
2024-09-16 19:01:05,124:INFO:DummyRegressor()
2024-09-16 19:01:05,124:INFO:create_model() successfully completed......................................
2024-09-16 19:01:05,214:INFO:SubProcess create_model() end ==================================
2024-09-16 19:01:05,215:INFO:Creating metrics dataframe
2024-09-16 19:01:05,221:WARNING:D:\grad-proj\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-09-16 19:01:05,224:INFO:Initializing create_model()
2024-09-16 19:01:05,224:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000114FDB21210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:01:05,224:INFO:Checking exceptions
2024-09-16 19:01:05,225:INFO:Importing libraries
2024-09-16 19:01:05,226:INFO:Copying training dataset
2024-09-16 19:01:05,235:INFO:Defining folds
2024-09-16 19:01:05,235:INFO:Declaring metric variables
2024-09-16 19:01:05,236:INFO:Importing untrained model
2024-09-16 19:01:05,236:INFO:Declaring custom model
2024-09-16 19:01:05,237:INFO:Random Forest Regressor Imported successfully
2024-09-16 19:01:05,245:INFO:Cross validation set to False
2024-09-16 19:01:05,245:INFO:Fitting Model
2024-09-16 19:01:09,038:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-09-16 19:01:09,038:INFO:create_model() successfully completed......................................
2024-09-16 19:01:09,141:INFO:_master_model_container: 18
2024-09-16 19:01:09,141:INFO:_display_container: 2
2024-09-16 19:01:09,142:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-09-16 19:01:09,142:INFO:compare_models() successfully completed......................................
2024-09-16 19:01:09,155:INFO:Initializing save_model()
2024-09-16 19:01:09,155:INFO:save_model(model=RandomForestRegressor(n_jobs=-1, random_state=123), model_name=D:\Grad-proj\ML\my_model_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Dell\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['long', 'lat', 'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['city', 'neighborhood',
                                             'subcategory', 'facade',
                                             'payment_method', 'bedrooms',
                                             'bathrooms', 'furnished', 'floor',
                                             'building_...
                                             'bathrooms', 'furnished', 'floor',
                                             'building_age'],
                                    transformer=OneHotEncoder(cols=['city',
                                                                    'subcategory',
                                                                    'facade',
                                                                    'payment_method',
                                                                    'bedrooms',
                                                                    'bathrooms',
                                                                    'furnished',
                                                                    'floor',
                                                                    'building_age'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['neighborhood'],
                                    transformer=TargetEncoder(cols=['neighborhood'],
                                                              handle_missing='return_nan')))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2024-09-16 19:01:09,155:INFO:Adding model into prep_pipe
2024-09-16 19:01:09,246:INFO:D:\Grad-proj\ML\my_model_pipeline.pkl saved in current working directory
2024-09-16 19:01:09,261:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['long', 'lat', 'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['city', 'neighborhood',
                                             'subcategory', 'facade',
                                             'payment_method', 'bedrooms',
                                             'bathrooms', 'furnished', 'floor',
                                             'building_age'],
                                    transformer=SimpleImputer(strateg...
                                                                    'subcategory',
                                                                    'facade',
                                                                    'payment_method',
                                                                    'bedrooms',
                                                                    'bathrooms',
                                                                    'furnished',
                                                                    'floor',
                                                                    'building_age'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['neighborhood'],
                                    transformer=TargetEncoder(cols=['neighborhood'],
                                                              handle_missing='return_nan'))),
                ('trained_model',
                 RandomForestRegressor(n_jobs=-1, random_state=123))])
2024-09-16 19:01:09,261:INFO:save_model() successfully completed......................................
2024-09-16 19:11:08,079:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-16 19:11:08,080:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-16 19:11:08,080:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-16 19:11:08,080:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-16 19:12:00,131:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-16 19:12:00,131:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-16 19:12:00,131:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-16 19:12:00,131:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-16 19:12:00,766:INFO:PyCaret RegressionExperiment
2024-09-16 19:12:00,767:INFO:Logging name: reg-default-name
2024-09-16 19:12:00,767:INFO:ML Usecase: MLUsecase.REGRESSION
2024-09-16 19:12:00,767:INFO:version 3.3.2
2024-09-16 19:12:00,767:INFO:Initializing setup()
2024-09-16 19:12:00,767:INFO:self.USI: efa7
2024-09-16 19:12:00,767:INFO:self._variable_keys: {'fold_groups_param', 'y_train', 'X_train', '_available_plots', 'exp_id', 'X_test', '_ml_usecase', 'log_plots_param', 'fold_shuffle_param', 'y_test', 'logging_param', 'y', 'target_param', 'USI', 'memory', 'data', 'gpu_param', 'pipeline', 'html_param', 'n_jobs_param', 'gpu_n_jobs_param', 'fold_generator', 'seed', 'transform_target_param', 'exp_name_log', 'idx', 'X'}
2024-09-16 19:12:00,767:INFO:Checking environment
2024-09-16 19:12:00,767:INFO:python_version: 3.11.3
2024-09-16 19:12:00,767:INFO:python_build: ('tags/v3.11.3:f3909b8', 'Apr  4 2023 23:49:59')
2024-09-16 19:12:00,767:INFO:machine: AMD64
2024-09-16 19:12:00,792:INFO:platform: Windows-10-10.0.19045-SP0
2024-09-16 19:12:00,796:INFO:Memory: svmem(total=8459001856, available=1027084288, percent=87.9, used=7431917568, free=1027084288)
2024-09-16 19:12:00,796:INFO:Physical Core: 2
2024-09-16 19:12:00,796:INFO:Logical Core: 4
2024-09-16 19:12:00,797:INFO:Checking libraries
2024-09-16 19:12:00,797:INFO:System:
2024-09-16 19:12:00,797:INFO:    python: 3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]
2024-09-16 19:12:00,797:INFO:executable: D:\grad-proj\Scripts\python.exe
2024-09-16 19:12:00,797:INFO:   machine: Windows-10-10.0.19045-SP0
2024-09-16 19:12:00,797:INFO:PyCaret required dependencies:
2024-09-16 19:12:00,853:INFO:                 pip: 22.3.1
2024-09-16 19:12:00,854:INFO:          setuptools: 65.5.0
2024-09-16 19:12:00,854:INFO:             pycaret: 3.3.2
2024-09-16 19:12:00,854:INFO:             IPython: 8.27.0
2024-09-16 19:12:00,854:INFO:          ipywidgets: 8.1.5
2024-09-16 19:12:00,854:INFO:                tqdm: 4.66.5
2024-09-16 19:12:00,854:INFO:               numpy: 1.26.4
2024-09-16 19:12:00,854:INFO:              pandas: 2.1.4
2024-09-16 19:12:00,854:INFO:              jinja2: 3.1.4
2024-09-16 19:12:00,854:INFO:               scipy: 1.11.4
2024-09-16 19:12:00,854:INFO:              joblib: 1.3.2
2024-09-16 19:12:00,854:INFO:             sklearn: 1.4.2
2024-09-16 19:12:00,854:INFO:                pyod: 2.0.2
2024-09-16 19:12:00,854:INFO:            imblearn: 0.12.3
2024-09-16 19:12:00,854:INFO:   category_encoders: 2.6.3
2024-09-16 19:12:00,854:INFO:            lightgbm: 4.5.0
2024-09-16 19:12:00,855:INFO:               numba: 0.60.0
2024-09-16 19:12:00,855:INFO:            requests: 2.32.3
2024-09-16 19:12:00,855:INFO:          matplotlib: 3.7.5
2024-09-16 19:12:00,855:INFO:          scikitplot: 0.3.7
2024-09-16 19:12:00,855:INFO:         yellowbrick: 1.5
2024-09-16 19:12:00,855:INFO:              plotly: 5.24.1
2024-09-16 19:12:00,855:INFO:    plotly-resampler: Not installed
2024-09-16 19:12:00,855:INFO:             kaleido: 0.2.1
2024-09-16 19:12:00,855:INFO:           schemdraw: 0.15
2024-09-16 19:12:00,855:INFO:         statsmodels: 0.14.3
2024-09-16 19:12:00,855:INFO:              sktime: 0.26.0
2024-09-16 19:12:00,855:INFO:               tbats: 1.1.3
2024-09-16 19:12:00,855:INFO:            pmdarima: 2.0.4
2024-09-16 19:12:00,855:INFO:              psutil: 6.0.0
2024-09-16 19:12:00,855:INFO:          markupsafe: 2.1.5
2024-09-16 19:12:00,855:INFO:             pickle5: Not installed
2024-09-16 19:12:00,855:INFO:         cloudpickle: 3.0.0
2024-09-16 19:12:00,855:INFO:         deprecation: 2.1.0
2024-09-16 19:12:00,856:INFO:              xxhash: 3.5.0
2024-09-16 19:12:00,856:INFO:           wurlitzer: Not installed
2024-09-16 19:12:00,856:INFO:PyCaret optional dependencies:
2024-09-16 19:12:00,901:INFO:                shap: Not installed
2024-09-16 19:12:00,901:INFO:           interpret: Not installed
2024-09-16 19:12:00,901:INFO:                umap: Not installed
2024-09-16 19:12:00,901:INFO:     ydata_profiling: Not installed
2024-09-16 19:12:00,901:INFO:  explainerdashboard: Not installed
2024-09-16 19:12:00,902:INFO:             autoviz: Not installed
2024-09-16 19:12:00,902:INFO:           fairlearn: Not installed
2024-09-16 19:12:00,902:INFO:          deepchecks: Not installed
2024-09-16 19:12:00,902:INFO:             xgboost: Not installed
2024-09-16 19:12:00,902:INFO:            catboost: Not installed
2024-09-16 19:12:00,902:INFO:              kmodes: Not installed
2024-09-16 19:12:00,902:INFO:             mlxtend: Not installed
2024-09-16 19:12:00,902:INFO:       statsforecast: Not installed
2024-09-16 19:12:00,902:INFO:        tune_sklearn: Not installed
2024-09-16 19:12:00,902:INFO:                 ray: Not installed
2024-09-16 19:12:00,902:INFO:            hyperopt: Not installed
2024-09-16 19:12:00,902:INFO:              optuna: Not installed
2024-09-16 19:12:00,902:INFO:               skopt: Not installed
2024-09-16 19:12:00,902:INFO:              mlflow: Not installed
2024-09-16 19:12:00,902:INFO:              gradio: Not installed
2024-09-16 19:12:00,902:INFO:             fastapi: Not installed
2024-09-16 19:12:00,903:INFO:             uvicorn: Not installed
2024-09-16 19:12:00,903:INFO:              m2cgen: Not installed
2024-09-16 19:12:00,903:INFO:           evidently: Not installed
2024-09-16 19:12:00,903:INFO:               fugue: Not installed
2024-09-16 19:12:00,903:INFO:           streamlit: Not installed
2024-09-16 19:12:00,903:INFO:             prophet: Not installed
2024-09-16 19:12:00,903:INFO:None
2024-09-16 19:12:00,903:INFO:Set up data.
2024-09-16 19:12:00,940:INFO:Set up folding strategy.
2024-09-16 19:12:00,940:INFO:Set up train/test split.
2024-09-16 19:12:00,956:INFO:Set up index.
2024-09-16 19:12:00,956:INFO:Assigning column types.
2024-09-16 19:12:00,962:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-16 19:12:00,962:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-09-16 19:12:00,969:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-09-16 19:12:00,975:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-09-16 19:12:01,067:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 19:12:01,132:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-16 19:12:01,133:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:12:01,133:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:12:01,133:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-09-16 19:12:01,140:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-09-16 19:12:01,147:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-09-16 19:12:01,235:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 19:12:01,307:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-16 19:12:01,307:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:12:01,308:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:12:01,308:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-09-16 19:12:01,315:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-09-16 19:12:01,322:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-09-16 19:12:01,405:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 19:12:01,467:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-16 19:12:01,468:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:12:01,468:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:12:01,475:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-09-16 19:12:01,482:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-09-16 19:12:01,566:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 19:12:01,631:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-16 19:12:01,632:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:12:01,633:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:12:01,633:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-09-16 19:12:01,646:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-09-16 19:12:01,736:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 19:12:01,800:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-16 19:12:01,800:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:12:01,801:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:12:01,815:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-09-16 19:12:01,994:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 19:12:02,155:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-16 19:12:02,156:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:12:02,156:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:12:02,157:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-09-16 19:12:02,274:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 19:12:02,344:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-16 19:12:02,345:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:12:02,345:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:12:02,449:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 19:12:02,516:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-16 19:12:02,517:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:12:02,517:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:12:02,518:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-16 19:12:02,625:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 19:12:02,695:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:12:02,695:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:12:02,806:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 19:12:02,878:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:12:02,878:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:12:02,879:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-09-16 19:12:03,053:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:12:03,053:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:12:03,225:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:12:03,226:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:12:03,230:INFO:Preparing preprocessing pipeline...
2024-09-16 19:12:03,230:INFO:Set up simple imputation.
2024-09-16 19:12:03,237:INFO:Set up encoding of categorical features.
2024-09-16 19:12:03,541:INFO:Finished creating preprocessing pipeline.
2024-09-16 19:12:03,556:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Dell\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['long', 'lat', 'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['city', 'neighborhood',
                                             'subcategory', 'facade',
                                             'payment_method', 'bedrooms',
                                             'bathrooms', 'furnished', 'floor',
                                             'building_...
                                             'bathrooms', 'furnished', 'floor',
                                             'building_age'],
                                    transformer=OneHotEncoder(cols=['city',
                                                                    'subcategory',
                                                                    'facade',
                                                                    'payment_method',
                                                                    'bedrooms',
                                                                    'bathrooms',
                                                                    'furnished',
                                                                    'floor',
                                                                    'building_age'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['neighborhood'],
                                    transformer=TargetEncoder(cols=['neighborhood'],
                                                              handle_missing='return_nan')))])
2024-09-16 19:12:03,556:INFO:Creating final display dataframe.
2024-09-16 19:12:04,450:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             price
2                   Target type        Regression
3           Original data shape        (8513, 14)
4        Transformed data shape        (8513, 96)
5   Transformed train set shape        (5959, 96)
6    Transformed test set shape        (2554, 96)
7              Numeric features                 3
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              efa7
2024-09-16 19:12:04,623:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:12:04,623:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:12:04,795:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:12:04,795:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:12:04,796:INFO:setup() successfully completed in 4.04s...............
2024-09-16 19:12:04,797:INFO:Initializing compare_models()
2024-09-16 19:12:04,797:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000185C6276510>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000185C6276510>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2024-09-16 19:12:04,797:INFO:Checking exceptions
2024-09-16 19:12:04,799:INFO:Preparing display monitor
2024-09-16 19:12:04,803:INFO:Initializing Linear Regression
2024-09-16 19:12:04,803:INFO:Total runtime is 0.0 minutes
2024-09-16 19:12:04,803:INFO:SubProcess create_model() called ==================================
2024-09-16 19:12:04,804:INFO:Initializing create_model()
2024-09-16 19:12:04,804:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000185C6276510>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000185C7007850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:12:04,804:INFO:Checking exceptions
2024-09-16 19:12:04,804:INFO:Importing libraries
2024-09-16 19:12:04,804:INFO:Copying training dataset
2024-09-16 19:12:04,814:INFO:Defining folds
2024-09-16 19:12:04,814:INFO:Declaring metric variables
2024-09-16 19:12:04,814:INFO:Importing untrained model
2024-09-16 19:12:04,814:INFO:Linear Regression Imported successfully
2024-09-16 19:12:04,815:INFO:Starting cross validation
2024-09-16 19:12:04,834:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:12:17,209:INFO:Calculating mean and std
2024-09-16 19:12:17,211:INFO:Creating metrics dataframe
2024-09-16 19:12:17,213:INFO:Uploading results into container
2024-09-16 19:12:17,214:INFO:Uploading model into container now
2024-09-16 19:12:17,214:INFO:_master_model_container: 1
2024-09-16 19:12:17,215:INFO:_display_container: 2
2024-09-16 19:12:17,215:INFO:LinearRegression(n_jobs=-1)
2024-09-16 19:12:17,215:INFO:create_model() successfully completed......................................
2024-09-16 19:12:17,304:INFO:SubProcess create_model() end ==================================
2024-09-16 19:12:17,304:INFO:Creating metrics dataframe
2024-09-16 19:12:17,308:INFO:Initializing Lasso Regression
2024-09-16 19:12:17,308:INFO:Total runtime is 0.20841808319091798 minutes
2024-09-16 19:12:17,308:INFO:SubProcess create_model() called ==================================
2024-09-16 19:12:17,308:INFO:Initializing create_model()
2024-09-16 19:12:17,308:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000185C6276510>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000185C7007850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:12:17,309:INFO:Checking exceptions
2024-09-16 19:12:17,309:INFO:Importing libraries
2024-09-16 19:12:17,309:INFO:Copying training dataset
2024-09-16 19:12:17,317:INFO:Defining folds
2024-09-16 19:12:17,317:INFO:Declaring metric variables
2024-09-16 19:12:17,317:INFO:Importing untrained model
2024-09-16 19:12:17,318:INFO:Lasso Regression Imported successfully
2024-09-16 19:12:17,318:INFO:Starting cross validation
2024-09-16 19:12:17,321:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:12:19,992:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.188e+14, tolerance: 1.331e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 19:12:19,999:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.294e+14, tolerance: 1.117e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 19:12:20,011:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.201e+14, tolerance: 1.340e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 19:12:20,040:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.137e+14, tolerance: 1.323e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 19:12:22,772:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.255e+14, tolerance: 1.343e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 19:12:22,903:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.939e+14, tolerance: 1.272e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 19:12:22,906:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.306e+14, tolerance: 9.170e+10
  model = cd_fast.enet_coordinate_descent(

2024-09-16 19:12:22,935:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.035e+14, tolerance: 1.303e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 19:12:24,629:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.022e+14, tolerance: 1.288e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 19:12:24,701:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.888e+14, tolerance: 1.268e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 19:12:24,810:INFO:Calculating mean and std
2024-09-16 19:12:24,811:INFO:Creating metrics dataframe
2024-09-16 19:12:24,815:INFO:Uploading results into container
2024-09-16 19:12:24,816:INFO:Uploading model into container now
2024-09-16 19:12:24,816:INFO:_master_model_container: 2
2024-09-16 19:12:24,816:INFO:_display_container: 2
2024-09-16 19:12:24,816:INFO:Lasso(random_state=123)
2024-09-16 19:12:24,817:INFO:create_model() successfully completed......................................
2024-09-16 19:12:24,898:INFO:SubProcess create_model() end ==================================
2024-09-16 19:12:24,898:INFO:Creating metrics dataframe
2024-09-16 19:12:24,902:INFO:Initializing Ridge Regression
2024-09-16 19:12:24,902:INFO:Total runtime is 0.33497742414474485 minutes
2024-09-16 19:12:24,902:INFO:SubProcess create_model() called ==================================
2024-09-16 19:12:24,902:INFO:Initializing create_model()
2024-09-16 19:12:24,902:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000185C6276510>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000185C7007850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:12:24,902:INFO:Checking exceptions
2024-09-16 19:12:24,902:INFO:Importing libraries
2024-09-16 19:12:24,903:INFO:Copying training dataset
2024-09-16 19:12:24,912:INFO:Defining folds
2024-09-16 19:12:24,912:INFO:Declaring metric variables
2024-09-16 19:12:24,912:INFO:Importing untrained model
2024-09-16 19:12:24,912:INFO:Ridge Regression Imported successfully
2024-09-16 19:12:24,913:INFO:Starting cross validation
2024-09-16 19:12:24,916:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:12:25,578:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.1653e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 19:12:25,580:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.31329e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 19:12:25,609:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.16211e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 19:12:26,328:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.16155e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 19:12:26,346:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.15281e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 19:12:26,385:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.14216e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 19:12:26,440:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.1704e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 19:12:26,964:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.16082e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 19:12:27,079:INFO:Calculating mean and std
2024-09-16 19:12:27,080:INFO:Creating metrics dataframe
2024-09-16 19:12:27,082:INFO:Uploading results into container
2024-09-16 19:12:27,083:INFO:Uploading model into container now
2024-09-16 19:12:27,083:INFO:_master_model_container: 3
2024-09-16 19:12:27,083:INFO:_display_container: 2
2024-09-16 19:12:27,084:INFO:Ridge(random_state=123)
2024-09-16 19:12:27,084:INFO:create_model() successfully completed......................................
2024-09-16 19:12:27,167:INFO:SubProcess create_model() end ==================================
2024-09-16 19:12:27,167:INFO:Creating metrics dataframe
2024-09-16 19:12:27,170:INFO:Initializing Elastic Net
2024-09-16 19:12:27,170:INFO:Total runtime is 0.37277456919352214 minutes
2024-09-16 19:12:27,170:INFO:SubProcess create_model() called ==================================
2024-09-16 19:12:27,171:INFO:Initializing create_model()
2024-09-16 19:12:27,171:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000185C6276510>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000185C7007850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:12:27,171:INFO:Checking exceptions
2024-09-16 19:12:27,171:INFO:Importing libraries
2024-09-16 19:12:27,171:INFO:Copying training dataset
2024-09-16 19:12:27,179:INFO:Defining folds
2024-09-16 19:12:27,179:INFO:Declaring metric variables
2024-09-16 19:12:27,179:INFO:Importing untrained model
2024-09-16 19:12:27,179:INFO:Elastic Net Imported successfully
2024-09-16 19:12:27,180:INFO:Starting cross validation
2024-09-16 19:12:27,183:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:12:29,397:INFO:Calculating mean and std
2024-09-16 19:12:29,398:INFO:Creating metrics dataframe
2024-09-16 19:12:29,400:INFO:Uploading results into container
2024-09-16 19:12:29,401:INFO:Uploading model into container now
2024-09-16 19:12:29,401:INFO:_master_model_container: 4
2024-09-16 19:12:29,402:INFO:_display_container: 2
2024-09-16 19:12:29,402:INFO:ElasticNet(random_state=123)
2024-09-16 19:12:29,402:INFO:create_model() successfully completed......................................
2024-09-16 19:12:29,485:INFO:SubProcess create_model() end ==================================
2024-09-16 19:12:29,485:INFO:Creating metrics dataframe
2024-09-16 19:12:29,489:INFO:Initializing Least Angle Regression
2024-09-16 19:12:29,489:INFO:Total runtime is 0.4114363749821981 minutes
2024-09-16 19:12:29,490:INFO:SubProcess create_model() called ==================================
2024-09-16 19:12:29,490:INFO:Initializing create_model()
2024-09-16 19:12:29,490:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000185C6276510>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000185C7007850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:12:29,490:INFO:Checking exceptions
2024-09-16 19:12:29,490:INFO:Importing libraries
2024-09-16 19:12:29,490:INFO:Copying training dataset
2024-09-16 19:12:29,497:INFO:Defining folds
2024-09-16 19:12:29,497:INFO:Declaring metric variables
2024-09-16 19:12:29,497:INFO:Importing untrained model
2024-09-16 19:12:29,498:INFO:Least Angle Regression Imported successfully
2024-09-16 19:12:29,498:INFO:Starting cross validation
2024-09-16 19:12:29,502:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:12:30,200:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=7.507e+02, with an active set of 51 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,201:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=6.766e+02, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,203:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=7.454e+02, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,204:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=5.117e+02, with an active set of 48 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,204:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=7.398e+02, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,205:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=6.903e+02, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,209:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=4.506e+02, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,209:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=6.115e+02, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,211:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=1.119e+03, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,212:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=7.938e+02, with an active set of 60 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,213:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=7.735e+02, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,215:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 82 iterations, i.e. alpha=5.650e+02, with an active set of 69 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,219:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=5.678e+03, with an active set of 77 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,220:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=5.551e+03, with an active set of 78 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,222:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=8.438e+02, with an active set of 81 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,223:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=6.889e+02, with an active set of 81 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,224:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=4.405e+04, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,224:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=6.362e+02, with an active set of 83 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,225:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=5.884e+02, with an active set of 84 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,226:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=4.347e+02, with an active set of 85 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,226:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=3.550e+02, with an active set of 85 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,226:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=2.817e+04, with an active set of 91 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,227:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=2.184e+02, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,228:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=1.207e+02, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,228:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=4.569e+04, with an active set of 93 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,228:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=4.657e+01, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,229:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=2.705e+03, with an active set of 91 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,229:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=2.065e+01, with an active set of 87 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,231:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=1.709e+03, with an active set of 93 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,232:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=1.009e+03, with an active set of 93 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,233:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=1.377e+01, with an active set of 89 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,233:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=9.817e+00, with an active set of 89 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,234:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=6.965e+00, with an active set of 90 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,234:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=6.700e+00, with an active set of 90 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:30,235:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=2.479e+00, with an active set of 90 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:31,069:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=9.048e+02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:31,073:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.101e+03, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:31,074:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=9.455e+02, with an active set of 44 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:31,112:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=5.990e+02, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:31,137:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=1.805e+09, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:31,140:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=1.419e+09, with an active set of 91 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:31,142:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=4.235e+08, with an active set of 93 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:32,018:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=7.038e+03, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:32,289:INFO:Calculating mean and std
2024-09-16 19:12:32,290:INFO:Creating metrics dataframe
2024-09-16 19:12:32,294:INFO:Uploading results into container
2024-09-16 19:12:32,295:INFO:Uploading model into container now
2024-09-16 19:12:32,296:INFO:_master_model_container: 5
2024-09-16 19:12:32,296:INFO:_display_container: 2
2024-09-16 19:12:32,296:INFO:Lars(random_state=123)
2024-09-16 19:12:32,296:INFO:create_model() successfully completed......................................
2024-09-16 19:12:32,388:INFO:SubProcess create_model() end ==================================
2024-09-16 19:12:32,388:INFO:Creating metrics dataframe
2024-09-16 19:12:32,394:INFO:Initializing Lasso Least Angle Regression
2024-09-16 19:12:32,394:INFO:Total runtime is 0.4598452687263489 minutes
2024-09-16 19:12:32,394:INFO:SubProcess create_model() called ==================================
2024-09-16 19:12:32,395:INFO:Initializing create_model()
2024-09-16 19:12:32,395:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000185C6276510>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000185C7007850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:12:32,395:INFO:Checking exceptions
2024-09-16 19:12:32,395:INFO:Importing libraries
2024-09-16 19:12:32,395:INFO:Copying training dataset
2024-09-16 19:12:32,404:INFO:Defining folds
2024-09-16 19:12:32,404:INFO:Declaring metric variables
2024-09-16 19:12:32,404:INFO:Importing untrained model
2024-09-16 19:12:32,405:INFO:Lasso Least Angle Regression Imported successfully
2024-09-16 19:12:32,405:INFO:Starting cross validation
2024-09-16 19:12:32,411:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:12:33,204:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=3.070e+01, with an active set of 75 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:33,211:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=1.435e+02, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:33,212:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=1.180e+02, with an active set of 60 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:33,229:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 98 iterations, alpha=1.535e+01, previous alpha=1.535e+01, with an active set of 81 regressors.
  warnings.warn(

2024-09-16 19:12:33,244:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 82 iterations, alpha=9.372e+01, previous alpha=7.755e+01, with an active set of 73 regressors.
  warnings.warn(

2024-09-16 19:12:33,251:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 108 iterations, alpha=2.212e+00, previous alpha=2.212e+00, with an active set of 81 regressors.
  warnings.warn(

2024-09-16 19:12:34,272:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 102 iterations, alpha=9.960e+00, previous alpha=5.387e+00, with an active set of 79 regressors.
  warnings.warn(

2024-09-16 19:12:34,280:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=2.452e+01, with an active set of 75 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:34,285:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 101 iterations, alpha=1.817e+01, previous alpha=1.817e+01, with an active set of 76 regressors.
  warnings.warn(

2024-09-16 19:12:34,307:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=1.548e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:34,308:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=1.044e+01, with an active set of 77 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:34,317:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 108 iterations, alpha=5.444e+00, previous alpha=5.444e+00, with an active set of 79 regressors.
  warnings.warn(

2024-09-16 19:12:34,839:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=2.071e+02, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:34,840:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=1.952e+02, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:34,842:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=1.306e+02, with an active set of 61 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:12:34,843:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 68 iterations, alpha=1.363e+02, previous alpha=1.306e+02, with an active set of 61 regressors.
  warnings.warn(

2024-09-16 19:12:34,872:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 99 iterations, alpha=2.537e+01, previous alpha=2.533e+01, with an active set of 78 regressors.
  warnings.warn(

2024-09-16 19:12:34,956:INFO:Calculating mean and std
2024-09-16 19:12:34,957:INFO:Creating metrics dataframe
2024-09-16 19:12:34,959:INFO:Uploading results into container
2024-09-16 19:12:34,960:INFO:Uploading model into container now
2024-09-16 19:12:34,960:INFO:_master_model_container: 6
2024-09-16 19:12:34,960:INFO:_display_container: 2
2024-09-16 19:12:34,960:INFO:LassoLars(random_state=123)
2024-09-16 19:12:34,961:INFO:create_model() successfully completed......................................
2024-09-16 19:12:35,042:INFO:SubProcess create_model() end ==================================
2024-09-16 19:12:35,042:INFO:Creating metrics dataframe
2024-09-16 19:12:35,046:INFO:Initializing Orthogonal Matching Pursuit
2024-09-16 19:12:35,046:INFO:Total runtime is 0.5040543953577677 minutes
2024-09-16 19:12:35,046:INFO:SubProcess create_model() called ==================================
2024-09-16 19:12:35,046:INFO:Initializing create_model()
2024-09-16 19:12:35,046:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000185C6276510>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000185C7007850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:12:35,046:INFO:Checking exceptions
2024-09-16 19:12:35,046:INFO:Importing libraries
2024-09-16 19:12:35,046:INFO:Copying training dataset
2024-09-16 19:12:35,053:INFO:Defining folds
2024-09-16 19:12:35,054:INFO:Declaring metric variables
2024-09-16 19:12:35,054:INFO:Importing untrained model
2024-09-16 19:12:35,054:INFO:Orthogonal Matching Pursuit Imported successfully
2024-09-16 19:12:35,054:INFO:Starting cross validation
2024-09-16 19:12:35,058:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:12:37,156:INFO:Calculating mean and std
2024-09-16 19:12:37,157:INFO:Creating metrics dataframe
2024-09-16 19:12:37,159:INFO:Uploading results into container
2024-09-16 19:12:37,160:INFO:Uploading model into container now
2024-09-16 19:12:37,160:INFO:_master_model_container: 7
2024-09-16 19:12:37,160:INFO:_display_container: 2
2024-09-16 19:12:37,161:INFO:OrthogonalMatchingPursuit()
2024-09-16 19:12:37,161:INFO:create_model() successfully completed......................................
2024-09-16 19:12:37,246:INFO:SubProcess create_model() end ==================================
2024-09-16 19:12:37,246:INFO:Creating metrics dataframe
2024-09-16 19:12:37,249:INFO:Initializing Bayesian Ridge
2024-09-16 19:12:37,249:INFO:Total runtime is 0.540769636631012 minutes
2024-09-16 19:12:37,250:INFO:SubProcess create_model() called ==================================
2024-09-16 19:12:37,250:INFO:Initializing create_model()
2024-09-16 19:12:37,250:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000185C6276510>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000185C7007850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:12:37,251:INFO:Checking exceptions
2024-09-16 19:12:37,252:INFO:Importing libraries
2024-09-16 19:12:37,252:INFO:Copying training dataset
2024-09-16 19:12:37,270:INFO:Defining folds
2024-09-16 19:12:37,270:INFO:Declaring metric variables
2024-09-16 19:12:37,270:INFO:Importing untrained model
2024-09-16 19:12:37,271:INFO:Bayesian Ridge Imported successfully
2024-09-16 19:12:37,272:INFO:Starting cross validation
2024-09-16 19:12:37,276:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:12:40,602:INFO:Calculating mean and std
2024-09-16 19:12:40,603:INFO:Creating metrics dataframe
2024-09-16 19:12:40,605:INFO:Uploading results into container
2024-09-16 19:12:40,606:INFO:Uploading model into container now
2024-09-16 19:12:40,607:INFO:_master_model_container: 8
2024-09-16 19:12:40,607:INFO:_display_container: 2
2024-09-16 19:12:40,607:INFO:BayesianRidge()
2024-09-16 19:12:40,607:INFO:create_model() successfully completed......................................
2024-09-16 19:12:40,715:INFO:SubProcess create_model() end ==================================
2024-09-16 19:12:40,716:INFO:Creating metrics dataframe
2024-09-16 19:12:40,721:INFO:Initializing Passive Aggressive Regressor
2024-09-16 19:12:40,722:INFO:Total runtime is 0.5986521204312643 minutes
2024-09-16 19:12:40,722:INFO:SubProcess create_model() called ==================================
2024-09-16 19:12:40,722:INFO:Initializing create_model()
2024-09-16 19:12:40,722:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000185C6276510>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000185C7007850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:12:40,722:INFO:Checking exceptions
2024-09-16 19:12:40,722:INFO:Importing libraries
2024-09-16 19:12:40,722:INFO:Copying training dataset
2024-09-16 19:12:40,734:INFO:Defining folds
2024-09-16 19:12:40,734:INFO:Declaring metric variables
2024-09-16 19:12:40,735:INFO:Importing untrained model
2024-09-16 19:12:40,736:INFO:Passive Aggressive Regressor Imported successfully
2024-09-16 19:12:40,737:INFO:Starting cross validation
2024-09-16 19:12:40,743:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:12:43,120:INFO:Calculating mean and std
2024-09-16 19:12:43,121:INFO:Creating metrics dataframe
2024-09-16 19:12:43,123:INFO:Uploading results into container
2024-09-16 19:12:43,124:INFO:Uploading model into container now
2024-09-16 19:12:43,125:INFO:_master_model_container: 9
2024-09-16 19:12:43,125:INFO:_display_container: 2
2024-09-16 19:12:43,125:INFO:PassiveAggressiveRegressor(random_state=123)
2024-09-16 19:12:43,125:INFO:create_model() successfully completed......................................
2024-09-16 19:12:43,229:INFO:SubProcess create_model() end ==================================
2024-09-16 19:12:43,229:INFO:Creating metrics dataframe
2024-09-16 19:12:43,240:INFO:Initializing Huber Regressor
2024-09-16 19:12:43,240:INFO:Total runtime is 0.6406086643536886 minutes
2024-09-16 19:12:43,241:INFO:SubProcess create_model() called ==================================
2024-09-16 19:12:43,242:INFO:Initializing create_model()
2024-09-16 19:12:43,244:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000185C6276510>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000185C7007850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:12:43,244:INFO:Checking exceptions
2024-09-16 19:12:43,244:INFO:Importing libraries
2024-09-16 19:12:43,245:INFO:Copying training dataset
2024-09-16 19:12:43,267:INFO:Defining folds
2024-09-16 19:12:43,267:INFO:Declaring metric variables
2024-09-16 19:12:43,268:INFO:Importing untrained model
2024-09-16 19:12:43,268:INFO:Huber Regressor Imported successfully
2024-09-16 19:12:43,269:INFO:Starting cross validation
2024-09-16 19:12:43,274:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:12:46,780:INFO:Calculating mean and std
2024-09-16 19:12:46,781:INFO:Creating metrics dataframe
2024-09-16 19:12:46,783:INFO:Uploading results into container
2024-09-16 19:12:46,784:INFO:Uploading model into container now
2024-09-16 19:12:46,784:INFO:_master_model_container: 10
2024-09-16 19:12:46,785:INFO:_display_container: 2
2024-09-16 19:12:46,785:INFO:HuberRegressor()
2024-09-16 19:12:46,785:INFO:create_model() successfully completed......................................
2024-09-16 19:12:46,869:INFO:SubProcess create_model() end ==================================
2024-09-16 19:12:46,869:INFO:Creating metrics dataframe
2024-09-16 19:12:46,872:INFO:Initializing K Neighbors Regressor
2024-09-16 19:12:46,872:INFO:Total runtime is 0.7011507352193197 minutes
2024-09-16 19:12:46,872:INFO:SubProcess create_model() called ==================================
2024-09-16 19:12:46,873:INFO:Initializing create_model()
2024-09-16 19:12:46,873:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000185C6276510>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000185C7007850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:12:46,873:INFO:Checking exceptions
2024-09-16 19:12:46,873:INFO:Importing libraries
2024-09-16 19:12:46,873:INFO:Copying training dataset
2024-09-16 19:12:46,881:INFO:Defining folds
2024-09-16 19:12:46,881:INFO:Declaring metric variables
2024-09-16 19:12:46,881:INFO:Importing untrained model
2024-09-16 19:12:46,882:INFO:K Neighbors Regressor Imported successfully
2024-09-16 19:12:46,882:INFO:Starting cross validation
2024-09-16 19:12:46,886:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:12:49,593:INFO:Calculating mean and std
2024-09-16 19:12:49,594:INFO:Creating metrics dataframe
2024-09-16 19:12:49,596:INFO:Uploading results into container
2024-09-16 19:12:49,598:INFO:Uploading model into container now
2024-09-16 19:12:49,598:INFO:_master_model_container: 11
2024-09-16 19:12:49,599:INFO:_display_container: 2
2024-09-16 19:12:49,599:INFO:KNeighborsRegressor(n_jobs=-1)
2024-09-16 19:12:49,600:INFO:create_model() successfully completed......................................
2024-09-16 19:12:49,692:INFO:SubProcess create_model() end ==================================
2024-09-16 19:12:49,692:INFO:Creating metrics dataframe
2024-09-16 19:12:49,696:INFO:Initializing Decision Tree Regressor
2024-09-16 19:12:49,696:INFO:Total runtime is 0.7482065995534262 minutes
2024-09-16 19:12:49,696:INFO:SubProcess create_model() called ==================================
2024-09-16 19:12:49,696:INFO:Initializing create_model()
2024-09-16 19:12:49,696:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000185C6276510>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000185C7007850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:12:49,696:INFO:Checking exceptions
2024-09-16 19:12:49,696:INFO:Importing libraries
2024-09-16 19:12:49,697:INFO:Copying training dataset
2024-09-16 19:12:49,704:INFO:Defining folds
2024-09-16 19:12:49,704:INFO:Declaring metric variables
2024-09-16 19:12:49,704:INFO:Importing untrained model
2024-09-16 19:12:49,704:INFO:Decision Tree Regressor Imported successfully
2024-09-16 19:12:49,705:INFO:Starting cross validation
2024-09-16 19:12:49,708:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:12:52,654:INFO:Calculating mean and std
2024-09-16 19:12:52,655:INFO:Creating metrics dataframe
2024-09-16 19:12:52,657:INFO:Uploading results into container
2024-09-16 19:12:52,658:INFO:Uploading model into container now
2024-09-16 19:12:52,658:INFO:_master_model_container: 12
2024-09-16 19:12:52,658:INFO:_display_container: 2
2024-09-16 19:12:52,659:INFO:DecisionTreeRegressor(random_state=123)
2024-09-16 19:12:52,659:INFO:create_model() successfully completed......................................
2024-09-16 19:12:52,739:INFO:SubProcess create_model() end ==================================
2024-09-16 19:12:52,740:INFO:Creating metrics dataframe
2024-09-16 19:12:52,743:INFO:Initializing Random Forest Regressor
2024-09-16 19:12:52,743:INFO:Total runtime is 0.7990053494771322 minutes
2024-09-16 19:12:52,743:INFO:SubProcess create_model() called ==================================
2024-09-16 19:12:52,744:INFO:Initializing create_model()
2024-09-16 19:12:52,744:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000185C6276510>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000185C7007850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:12:52,744:INFO:Checking exceptions
2024-09-16 19:12:52,744:INFO:Importing libraries
2024-09-16 19:12:52,744:INFO:Copying training dataset
2024-09-16 19:12:52,751:INFO:Defining folds
2024-09-16 19:12:52,751:INFO:Declaring metric variables
2024-09-16 19:12:52,751:INFO:Importing untrained model
2024-09-16 19:12:52,752:INFO:Random Forest Regressor Imported successfully
2024-09-16 19:12:52,752:INFO:Starting cross validation
2024-09-16 19:12:52,755:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:13:26,747:INFO:Calculating mean and std
2024-09-16 19:13:26,748:INFO:Creating metrics dataframe
2024-09-16 19:13:26,751:INFO:Uploading results into container
2024-09-16 19:13:26,752:INFO:Uploading model into container now
2024-09-16 19:13:26,752:INFO:_master_model_container: 13
2024-09-16 19:13:26,752:INFO:_display_container: 2
2024-09-16 19:13:26,753:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-09-16 19:13:26,753:INFO:create_model() successfully completed......................................
2024-09-16 19:13:26,836:INFO:SubProcess create_model() end ==================================
2024-09-16 19:13:26,836:INFO:Creating metrics dataframe
2024-09-16 19:13:26,840:INFO:Initializing Extra Trees Regressor
2024-09-16 19:13:26,840:INFO:Total runtime is 1.3672876874605815 minutes
2024-09-16 19:13:26,840:INFO:SubProcess create_model() called ==================================
2024-09-16 19:13:26,840:INFO:Initializing create_model()
2024-09-16 19:13:26,840:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000185C6276510>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000185C7007850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:13:26,840:INFO:Checking exceptions
2024-09-16 19:13:26,840:INFO:Importing libraries
2024-09-16 19:13:26,841:INFO:Copying training dataset
2024-09-16 19:13:26,848:INFO:Defining folds
2024-09-16 19:13:26,849:INFO:Declaring metric variables
2024-09-16 19:13:26,849:INFO:Importing untrained model
2024-09-16 19:13:26,849:INFO:Extra Trees Regressor Imported successfully
2024-09-16 19:13:26,850:INFO:Starting cross validation
2024-09-16 19:13:26,853:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:14:00,994:INFO:Calculating mean and std
2024-09-16 19:14:00,995:INFO:Creating metrics dataframe
2024-09-16 19:14:00,998:INFO:Uploading results into container
2024-09-16 19:14:00,999:INFO:Uploading model into container now
2024-09-16 19:14:00,999:INFO:_master_model_container: 14
2024-09-16 19:14:00,999:INFO:_display_container: 2
2024-09-16 19:14:01,000:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-09-16 19:14:01,000:INFO:create_model() successfully completed......................................
2024-09-16 19:14:01,083:INFO:SubProcess create_model() end ==================================
2024-09-16 19:14:01,083:INFO:Creating metrics dataframe
2024-09-16 19:14:01,086:INFO:Initializing AdaBoost Regressor
2024-09-16 19:14:01,086:INFO:Total runtime is 1.9380445996920268 minutes
2024-09-16 19:14:01,086:INFO:SubProcess create_model() called ==================================
2024-09-16 19:14:01,087:INFO:Initializing create_model()
2024-09-16 19:14:01,087:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000185C6276510>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000185C7007850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:14:01,087:INFO:Checking exceptions
2024-09-16 19:14:01,087:INFO:Importing libraries
2024-09-16 19:14:01,087:INFO:Copying training dataset
2024-09-16 19:14:01,094:INFO:Defining folds
2024-09-16 19:14:01,094:INFO:Declaring metric variables
2024-09-16 19:14:01,094:INFO:Importing untrained model
2024-09-16 19:14:01,095:INFO:AdaBoost Regressor Imported successfully
2024-09-16 19:14:01,095:INFO:Starting cross validation
2024-09-16 19:14:01,099:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:14:08,802:INFO:Calculating mean and std
2024-09-16 19:14:08,803:INFO:Creating metrics dataframe
2024-09-16 19:14:08,805:INFO:Uploading results into container
2024-09-16 19:14:08,806:INFO:Uploading model into container now
2024-09-16 19:14:08,806:INFO:_master_model_container: 15
2024-09-16 19:14:08,806:INFO:_display_container: 2
2024-09-16 19:14:08,807:INFO:AdaBoostRegressor(random_state=123)
2024-09-16 19:14:08,807:INFO:create_model() successfully completed......................................
2024-09-16 19:14:08,890:INFO:SubProcess create_model() end ==================================
2024-09-16 19:14:08,890:INFO:Creating metrics dataframe
2024-09-16 19:14:08,894:INFO:Initializing Gradient Boosting Regressor
2024-09-16 19:14:08,894:INFO:Total runtime is 2.0681877652804057 minutes
2024-09-16 19:14:08,894:INFO:SubProcess create_model() called ==================================
2024-09-16 19:14:08,894:INFO:Initializing create_model()
2024-09-16 19:14:08,894:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000185C6276510>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000185C7007850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:14:08,894:INFO:Checking exceptions
2024-09-16 19:14:08,894:INFO:Importing libraries
2024-09-16 19:14:08,894:INFO:Copying training dataset
2024-09-16 19:14:08,901:INFO:Defining folds
2024-09-16 19:14:08,902:INFO:Declaring metric variables
2024-09-16 19:14:08,902:INFO:Importing untrained model
2024-09-16 19:14:08,902:INFO:Gradient Boosting Regressor Imported successfully
2024-09-16 19:14:08,903:INFO:Starting cross validation
2024-09-16 19:14:08,906:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:14:17,745:INFO:Calculating mean and std
2024-09-16 19:14:17,746:INFO:Creating metrics dataframe
2024-09-16 19:14:17,748:INFO:Uploading results into container
2024-09-16 19:14:17,749:INFO:Uploading model into container now
2024-09-16 19:14:17,750:INFO:_master_model_container: 16
2024-09-16 19:14:17,750:INFO:_display_container: 2
2024-09-16 19:14:17,750:INFO:GradientBoostingRegressor(random_state=123)
2024-09-16 19:14:17,750:INFO:create_model() successfully completed......................................
2024-09-16 19:14:17,838:INFO:SubProcess create_model() end ==================================
2024-09-16 19:14:17,838:INFO:Creating metrics dataframe
2024-09-16 19:14:17,843:INFO:Initializing Light Gradient Boosting Machine
2024-09-16 19:14:17,844:INFO:Total runtime is 2.2173507968584696 minutes
2024-09-16 19:14:17,844:INFO:SubProcess create_model() called ==================================
2024-09-16 19:14:17,844:INFO:Initializing create_model()
2024-09-16 19:14:17,845:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000185C6276510>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000185C7007850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:14:17,845:INFO:Checking exceptions
2024-09-16 19:14:17,845:INFO:Importing libraries
2024-09-16 19:14:17,845:INFO:Copying training dataset
2024-09-16 19:14:17,859:INFO:Defining folds
2024-09-16 19:14:17,859:INFO:Declaring metric variables
2024-09-16 19:14:17,860:INFO:Importing untrained model
2024-09-16 19:14:17,861:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-16 19:14:17,861:INFO:Starting cross validation
2024-09-16 19:14:17,865:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:14:21,640:INFO:Calculating mean and std
2024-09-16 19:14:21,642:INFO:Creating metrics dataframe
2024-09-16 19:14:21,645:INFO:Uploading results into container
2024-09-16 19:14:21,646:INFO:Uploading model into container now
2024-09-16 19:14:21,646:INFO:_master_model_container: 17
2024-09-16 19:14:21,647:INFO:_display_container: 2
2024-09-16 19:14:21,647:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-09-16 19:14:21,647:INFO:create_model() successfully completed......................................
2024-09-16 19:14:21,767:INFO:SubProcess create_model() end ==================================
2024-09-16 19:14:21,768:INFO:Creating metrics dataframe
2024-09-16 19:14:21,771:INFO:Initializing Dummy Regressor
2024-09-16 19:14:21,771:INFO:Total runtime is 2.282796816031138 minutes
2024-09-16 19:14:21,771:INFO:SubProcess create_model() called ==================================
2024-09-16 19:14:21,771:INFO:Initializing create_model()
2024-09-16 19:14:21,771:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000185C6276510>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000185C7007850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:14:21,772:INFO:Checking exceptions
2024-09-16 19:14:21,772:INFO:Importing libraries
2024-09-16 19:14:21,772:INFO:Copying training dataset
2024-09-16 19:14:21,779:INFO:Defining folds
2024-09-16 19:14:21,779:INFO:Declaring metric variables
2024-09-16 19:14:21,780:INFO:Importing untrained model
2024-09-16 19:14:21,780:INFO:Dummy Regressor Imported successfully
2024-09-16 19:14:21,780:INFO:Starting cross validation
2024-09-16 19:14:21,784:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:14:23,837:INFO:Calculating mean and std
2024-09-16 19:14:23,838:INFO:Creating metrics dataframe
2024-09-16 19:14:23,840:INFO:Uploading results into container
2024-09-16 19:14:23,841:INFO:Uploading model into container now
2024-09-16 19:14:23,841:INFO:_master_model_container: 18
2024-09-16 19:14:23,842:INFO:_display_container: 2
2024-09-16 19:14:23,842:INFO:DummyRegressor()
2024-09-16 19:14:23,842:INFO:create_model() successfully completed......................................
2024-09-16 19:14:23,925:INFO:SubProcess create_model() end ==================================
2024-09-16 19:14:23,925:INFO:Creating metrics dataframe
2024-09-16 19:14:23,932:WARNING:D:\grad-proj\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-09-16 19:14:23,934:INFO:Initializing create_model()
2024-09-16 19:14:23,934:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000185C6276510>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:14:23,934:INFO:Checking exceptions
2024-09-16 19:14:23,935:INFO:Importing libraries
2024-09-16 19:14:23,935:INFO:Copying training dataset
2024-09-16 19:14:23,942:INFO:Defining folds
2024-09-16 19:14:23,942:INFO:Declaring metric variables
2024-09-16 19:14:23,942:INFO:Importing untrained model
2024-09-16 19:14:23,942:INFO:Declaring custom model
2024-09-16 19:14:23,943:INFO:Random Forest Regressor Imported successfully
2024-09-16 19:14:23,949:INFO:Cross validation set to False
2024-09-16 19:14:23,949:INFO:Fitting Model
2024-09-16 19:14:27,587:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-09-16 19:14:27,587:INFO:create_model() successfully completed......................................
2024-09-16 19:14:27,711:INFO:_master_model_container: 18
2024-09-16 19:14:27,712:INFO:_display_container: 2
2024-09-16 19:14:27,712:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-09-16 19:14:27,712:INFO:compare_models() successfully completed......................................
2024-09-16 19:14:27,729:INFO:Initializing save_model()
2024-09-16 19:14:27,729:INFO:save_model(model=RandomForestRegressor(n_jobs=-1, random_state=123), model_name=D:\Grad-proj\ML\my_model_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Dell\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['long', 'lat', 'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['city', 'neighborhood',
                                             'subcategory', 'facade',
                                             'payment_method', 'bedrooms',
                                             'bathrooms', 'furnished', 'floor',
                                             'building_...
                                             'bathrooms', 'furnished', 'floor',
                                             'building_age'],
                                    transformer=OneHotEncoder(cols=['city',
                                                                    'subcategory',
                                                                    'facade',
                                                                    'payment_method',
                                                                    'bedrooms',
                                                                    'bathrooms',
                                                                    'furnished',
                                                                    'floor',
                                                                    'building_age'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['neighborhood'],
                                    transformer=TargetEncoder(cols=['neighborhood'],
                                                              handle_missing='return_nan')))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2024-09-16 19:14:27,730:INFO:Adding model into prep_pipe
2024-09-16 19:14:27,834:INFO:D:\Grad-proj\ML\my_model_pipeline.pkl saved in current working directory
2024-09-16 19:14:27,849:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['long', 'lat', 'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['city', 'neighborhood',
                                             'subcategory', 'facade',
                                             'payment_method', 'bedrooms',
                                             'bathrooms', 'furnished', 'floor',
                                             'building_age'],
                                    transformer=SimpleImputer(strateg...
                                                                    'subcategory',
                                                                    'facade',
                                                                    'payment_method',
                                                                    'bedrooms',
                                                                    'bathrooms',
                                                                    'furnished',
                                                                    'floor',
                                                                    'building_age'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['neighborhood'],
                                    transformer=TargetEncoder(cols=['neighborhood'],
                                                              handle_missing='return_nan'))),
                ('trained_model',
                 RandomForestRegressor(n_jobs=-1, random_state=123))])
2024-09-16 19:14:27,849:INFO:save_model() successfully completed......................................
2024-09-16 19:14:27,932:INFO:Initializing load_model()
2024-09-16 19:14:27,933:INFO:load_model(model_name=D:/Grad-proj/ML/my_model_pipeline, platform=None, authentication=None, verbose=True)
2024-09-16 19:21:31,149:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-16 19:21:31,149:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-16 19:21:31,150:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-16 19:21:31,150:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-16 19:21:32,005:INFO:PyCaret RegressionExperiment
2024-09-16 19:21:32,005:INFO:Logging name: reg-default-name
2024-09-16 19:21:32,005:INFO:ML Usecase: MLUsecase.REGRESSION
2024-09-16 19:21:32,006:INFO:version 3.3.2
2024-09-16 19:21:32,006:INFO:Initializing setup()
2024-09-16 19:21:32,006:INFO:self.USI: d8b8
2024-09-16 19:21:32,006:INFO:self._variable_keys: {'gpu_n_jobs_param', 'target_param', 'memory', 'pipeline', 'log_plots_param', 'logging_param', '_available_plots', 'y_test', 'exp_name_log', 'fold_groups_param', 'fold_shuffle_param', 'X', 'X_train', 'html_param', 'USI', 'fold_generator', '_ml_usecase', 'transform_target_param', 'y_train', 'idx', 'y', 'data', 'seed', 'exp_id', 'gpu_param', 'X_test', 'n_jobs_param'}
2024-09-16 19:21:32,006:INFO:Checking environment
2024-09-16 19:21:32,006:INFO:python_version: 3.11.3
2024-09-16 19:21:32,006:INFO:python_build: ('tags/v3.11.3:f3909b8', 'Apr  4 2023 23:49:59')
2024-09-16 19:21:32,006:INFO:machine: AMD64
2024-09-16 19:21:32,025:INFO:platform: Windows-10-10.0.19045-SP0
2024-09-16 19:21:32,028:INFO:Memory: svmem(total=8459001856, available=1234006016, percent=85.4, used=7224995840, free=1234006016)
2024-09-16 19:21:32,028:INFO:Physical Core: 2
2024-09-16 19:21:32,028:INFO:Logical Core: 4
2024-09-16 19:21:32,029:INFO:Checking libraries
2024-09-16 19:21:32,029:INFO:System:
2024-09-16 19:21:32,029:INFO:    python: 3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]
2024-09-16 19:21:32,029:INFO:executable: D:\grad-proj\Scripts\python.exe
2024-09-16 19:21:32,029:INFO:   machine: Windows-10-10.0.19045-SP0
2024-09-16 19:21:32,029:INFO:PyCaret required dependencies:
2024-09-16 19:21:32,076:INFO:                 pip: 22.3.1
2024-09-16 19:21:32,076:INFO:          setuptools: 65.5.0
2024-09-16 19:21:32,076:INFO:             pycaret: 3.3.2
2024-09-16 19:21:32,076:INFO:             IPython: 8.27.0
2024-09-16 19:21:32,076:INFO:          ipywidgets: 8.1.5
2024-09-16 19:21:32,076:INFO:                tqdm: 4.66.5
2024-09-16 19:21:32,076:INFO:               numpy: 1.26.4
2024-09-16 19:21:32,076:INFO:              pandas: 2.1.4
2024-09-16 19:21:32,077:INFO:              jinja2: 3.1.4
2024-09-16 19:21:32,077:INFO:               scipy: 1.11.4
2024-09-16 19:21:32,077:INFO:              joblib: 1.3.2
2024-09-16 19:21:32,077:INFO:             sklearn: 1.4.2
2024-09-16 19:21:32,077:INFO:                pyod: 2.0.2
2024-09-16 19:21:32,077:INFO:            imblearn: 0.12.3
2024-09-16 19:21:32,077:INFO:   category_encoders: 2.6.3
2024-09-16 19:21:32,077:INFO:            lightgbm: 4.5.0
2024-09-16 19:21:32,077:INFO:               numba: 0.60.0
2024-09-16 19:21:32,077:INFO:            requests: 2.32.3
2024-09-16 19:21:32,077:INFO:          matplotlib: 3.7.5
2024-09-16 19:21:32,077:INFO:          scikitplot: 0.3.7
2024-09-16 19:21:32,077:INFO:         yellowbrick: 1.5
2024-09-16 19:21:32,077:INFO:              plotly: 5.24.1
2024-09-16 19:21:32,077:INFO:    plotly-resampler: Not installed
2024-09-16 19:21:32,077:INFO:             kaleido: 0.2.1
2024-09-16 19:21:32,077:INFO:           schemdraw: 0.15
2024-09-16 19:21:32,078:INFO:         statsmodels: 0.14.3
2024-09-16 19:21:32,078:INFO:              sktime: 0.26.0
2024-09-16 19:21:32,078:INFO:               tbats: 1.1.3
2024-09-16 19:21:32,078:INFO:            pmdarima: 2.0.4
2024-09-16 19:21:32,078:INFO:              psutil: 6.0.0
2024-09-16 19:21:32,078:INFO:          markupsafe: 2.1.5
2024-09-16 19:21:32,078:INFO:             pickle5: Not installed
2024-09-16 19:21:32,078:INFO:         cloudpickle: 3.0.0
2024-09-16 19:21:32,078:INFO:         deprecation: 2.1.0
2024-09-16 19:21:32,078:INFO:              xxhash: 3.5.0
2024-09-16 19:21:32,078:INFO:           wurlitzer: Not installed
2024-09-16 19:21:32,078:INFO:PyCaret optional dependencies:
2024-09-16 19:21:32,125:INFO:                shap: Not installed
2024-09-16 19:21:32,126:INFO:           interpret: Not installed
2024-09-16 19:21:32,126:INFO:                umap: Not installed
2024-09-16 19:21:32,126:INFO:     ydata_profiling: Not installed
2024-09-16 19:21:32,126:INFO:  explainerdashboard: Not installed
2024-09-16 19:21:32,126:INFO:             autoviz: Not installed
2024-09-16 19:21:32,126:INFO:           fairlearn: Not installed
2024-09-16 19:21:32,126:INFO:          deepchecks: Not installed
2024-09-16 19:21:32,126:INFO:             xgboost: Not installed
2024-09-16 19:21:32,126:INFO:            catboost: Not installed
2024-09-16 19:21:32,126:INFO:              kmodes: Not installed
2024-09-16 19:21:32,126:INFO:             mlxtend: Not installed
2024-09-16 19:21:32,126:INFO:       statsforecast: Not installed
2024-09-16 19:21:32,126:INFO:        tune_sklearn: Not installed
2024-09-16 19:21:32,126:INFO:                 ray: Not installed
2024-09-16 19:21:32,126:INFO:            hyperopt: Not installed
2024-09-16 19:21:32,126:INFO:              optuna: Not installed
2024-09-16 19:21:32,126:INFO:               skopt: Not installed
2024-09-16 19:21:32,127:INFO:              mlflow: Not installed
2024-09-16 19:21:32,127:INFO:              gradio: Not installed
2024-09-16 19:21:32,127:INFO:             fastapi: Not installed
2024-09-16 19:21:32,127:INFO:             uvicorn: Not installed
2024-09-16 19:21:32,127:INFO:              m2cgen: Not installed
2024-09-16 19:21:32,127:INFO:           evidently: Not installed
2024-09-16 19:21:32,127:INFO:               fugue: Not installed
2024-09-16 19:21:32,127:INFO:           streamlit: Not installed
2024-09-16 19:21:32,127:INFO:             prophet: Not installed
2024-09-16 19:21:32,127:INFO:None
2024-09-16 19:21:32,127:INFO:Set up data.
2024-09-16 19:21:32,165:INFO:Set up folding strategy.
2024-09-16 19:21:32,165:INFO:Set up train/test split.
2024-09-16 19:21:32,179:INFO:Set up index.
2024-09-16 19:21:32,179:INFO:Assigning column types.
2024-09-16 19:21:32,186:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-16 19:21:32,186:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-09-16 19:21:32,192:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-09-16 19:21:32,199:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-09-16 19:21:32,284:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 19:21:32,345:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-16 19:21:32,346:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:21:32,347:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:21:32,347:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-09-16 19:21:32,353:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-09-16 19:21:32,360:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-09-16 19:21:32,438:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 19:21:32,497:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-16 19:21:32,497:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:21:32,498:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:21:32,498:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-09-16 19:21:32,504:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-09-16 19:21:32,510:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-09-16 19:21:32,585:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 19:21:32,643:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-16 19:21:32,644:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:21:32,645:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:21:32,653:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-09-16 19:21:32,659:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-09-16 19:21:32,758:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 19:21:32,847:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-16 19:21:32,848:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:21:32,849:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:21:32,850:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-09-16 19:21:32,865:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-09-16 19:21:32,975:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 19:21:33,083:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-16 19:21:33,084:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:21:33,084:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:21:33,100:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-09-16 19:21:33,209:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 19:21:33,292:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-16 19:21:33,292:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:21:33,292:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:21:33,293:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-09-16 19:21:33,433:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 19:21:33,558:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-16 19:21:33,559:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:21:33,559:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:21:33,673:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 19:21:33,764:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-16 19:21:33,765:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:21:33,766:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:21:33,766:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-16 19:21:33,889:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 19:21:33,972:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:21:33,973:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:21:34,096:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 19:21:34,262:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:21:34,263:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:21:34,264:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-09-16 19:21:34,436:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:21:34,437:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:21:34,617:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:21:34,617:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:21:34,622:INFO:Preparing preprocessing pipeline...
2024-09-16 19:21:34,622:INFO:Set up simple imputation.
2024-09-16 19:21:34,633:INFO:Set up encoding of categorical features.
2024-09-16 19:21:35,248:INFO:Finished creating preprocessing pipeline.
2024-09-16 19:21:35,264:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Dell\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['long', 'lat', 'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['city', 'neighborhood',
                                             'subcategory', 'facade',
                                             'payment_method', 'bedrooms',
                                             'bathrooms', 'furnished', 'floor',
                                             'building_...
                                             'bathrooms', 'furnished', 'floor',
                                             'building_age'],
                                    transformer=OneHotEncoder(cols=['city',
                                                                    'subcategory',
                                                                    'facade',
                                                                    'payment_method',
                                                                    'bedrooms',
                                                                    'bathrooms',
                                                                    'furnished',
                                                                    'floor',
                                                                    'building_age'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['neighborhood'],
                                    transformer=TargetEncoder(cols=['neighborhood'],
                                                              handle_missing='return_nan')))])
2024-09-16 19:21:35,264:INFO:Creating final display dataframe.
2024-09-16 19:21:35,542:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             price
2                   Target type        Regression
3           Original data shape        (8513, 14)
4        Transformed data shape        (8513, 96)
5   Transformed train set shape        (5959, 96)
6    Transformed test set shape        (2554, 96)
7              Numeric features                 3
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              d8b8
2024-09-16 19:21:35,726:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:21:35,726:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:21:35,932:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:21:35,932:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:21:35,933:INFO:setup() successfully completed in 3.94s...............
2024-09-16 19:21:35,933:INFO:Initializing compare_models()
2024-09-16 19:21:35,933:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011727C2DF50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000011727C2DF50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2024-09-16 19:21:35,933:INFO:Checking exceptions
2024-09-16 19:21:35,936:INFO:Preparing display monitor
2024-09-16 19:21:35,940:INFO:Initializing Linear Regression
2024-09-16 19:21:35,940:INFO:Total runtime is 0.0 minutes
2024-09-16 19:21:35,940:INFO:SubProcess create_model() called ==================================
2024-09-16 19:21:35,941:INFO:Initializing create_model()
2024-09-16 19:21:35,941:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011727C2DF50>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011738687350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:21:35,941:INFO:Checking exceptions
2024-09-16 19:21:35,941:INFO:Importing libraries
2024-09-16 19:21:35,941:INFO:Copying training dataset
2024-09-16 19:21:35,949:INFO:Defining folds
2024-09-16 19:21:35,950:INFO:Declaring metric variables
2024-09-16 19:21:35,950:INFO:Importing untrained model
2024-09-16 19:21:35,951:INFO:Linear Regression Imported successfully
2024-09-16 19:21:35,952:INFO:Starting cross validation
2024-09-16 19:21:35,968:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:21:47,885:INFO:Calculating mean and std
2024-09-16 19:21:47,886:INFO:Creating metrics dataframe
2024-09-16 19:21:47,889:INFO:Uploading results into container
2024-09-16 19:21:47,889:INFO:Uploading model into container now
2024-09-16 19:21:47,890:INFO:_master_model_container: 1
2024-09-16 19:21:47,890:INFO:_display_container: 2
2024-09-16 19:21:47,890:INFO:LinearRegression(n_jobs=-1)
2024-09-16 19:21:47,890:INFO:create_model() successfully completed......................................
2024-09-16 19:21:47,976:INFO:SubProcess create_model() end ==================================
2024-09-16 19:21:47,976:INFO:Creating metrics dataframe
2024-09-16 19:21:47,983:INFO:Initializing Lasso Regression
2024-09-16 19:21:47,983:INFO:Total runtime is 0.20071341594060263 minutes
2024-09-16 19:21:47,984:INFO:SubProcess create_model() called ==================================
2024-09-16 19:21:47,984:INFO:Initializing create_model()
2024-09-16 19:21:47,984:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011727C2DF50>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011738687350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:21:47,985:INFO:Checking exceptions
2024-09-16 19:21:47,985:INFO:Importing libraries
2024-09-16 19:21:47,985:INFO:Copying training dataset
2024-09-16 19:21:47,994:INFO:Defining folds
2024-09-16 19:21:47,994:INFO:Declaring metric variables
2024-09-16 19:21:47,994:INFO:Importing untrained model
2024-09-16 19:21:47,994:INFO:Lasso Regression Imported successfully
2024-09-16 19:21:47,995:INFO:Starting cross validation
2024-09-16 19:21:47,999:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:21:50,479:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.188e+14, tolerance: 1.331e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 19:21:50,575:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.294e+14, tolerance: 1.117e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 19:21:50,704:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.137e+14, tolerance: 1.323e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 19:21:50,714:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.201e+14, tolerance: 1.340e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 19:21:53,130:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.255e+14, tolerance: 1.343e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 19:21:53,319:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.939e+14, tolerance: 1.272e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 19:21:53,363:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.306e+14, tolerance: 9.170e+10
  model = cd_fast.enet_coordinate_descent(

2024-09-16 19:21:53,377:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.035e+14, tolerance: 1.303e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 19:21:55,063:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.022e+14, tolerance: 1.288e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 19:21:55,167:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.888e+14, tolerance: 1.268e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 19:21:55,243:INFO:Calculating mean and std
2024-09-16 19:21:55,244:INFO:Creating metrics dataframe
2024-09-16 19:21:55,246:INFO:Uploading results into container
2024-09-16 19:21:55,247:INFO:Uploading model into container now
2024-09-16 19:21:55,247:INFO:_master_model_container: 2
2024-09-16 19:21:55,248:INFO:_display_container: 2
2024-09-16 19:21:55,248:INFO:Lasso(random_state=123)
2024-09-16 19:21:55,248:INFO:create_model() successfully completed......................................
2024-09-16 19:21:55,328:INFO:SubProcess create_model() end ==================================
2024-09-16 19:21:55,329:INFO:Creating metrics dataframe
2024-09-16 19:21:55,332:INFO:Initializing Ridge Regression
2024-09-16 19:21:55,332:INFO:Total runtime is 0.32319387594858806 minutes
2024-09-16 19:21:55,332:INFO:SubProcess create_model() called ==================================
2024-09-16 19:21:55,333:INFO:Initializing create_model()
2024-09-16 19:21:55,333:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011727C2DF50>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011738687350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:21:55,333:INFO:Checking exceptions
2024-09-16 19:21:55,333:INFO:Importing libraries
2024-09-16 19:21:55,333:INFO:Copying training dataset
2024-09-16 19:21:55,340:INFO:Defining folds
2024-09-16 19:21:55,340:INFO:Declaring metric variables
2024-09-16 19:21:55,340:INFO:Importing untrained model
2024-09-16 19:21:55,341:INFO:Ridge Regression Imported successfully
2024-09-16 19:21:55,341:INFO:Starting cross validation
2024-09-16 19:21:55,344:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:21:55,977:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.31329e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 19:21:56,024:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.1653e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 19:21:56,066:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.16211e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 19:21:56,804:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.16155e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 19:21:56,876:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.15281e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 19:21:56,889:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.1704e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 19:21:56,966:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.14216e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 19:21:57,517:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.16172e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 19:21:57,623:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.16082e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 19:21:57,737:INFO:Calculating mean and std
2024-09-16 19:21:57,739:INFO:Creating metrics dataframe
2024-09-16 19:21:57,744:INFO:Uploading results into container
2024-09-16 19:21:57,745:INFO:Uploading model into container now
2024-09-16 19:21:57,746:INFO:_master_model_container: 3
2024-09-16 19:21:57,746:INFO:_display_container: 2
2024-09-16 19:21:57,747:INFO:Ridge(random_state=123)
2024-09-16 19:21:57,747:INFO:create_model() successfully completed......................................
2024-09-16 19:21:57,851:INFO:SubProcess create_model() end ==================================
2024-09-16 19:21:57,851:INFO:Creating metrics dataframe
2024-09-16 19:21:57,859:INFO:Initializing Elastic Net
2024-09-16 19:21:57,859:INFO:Total runtime is 0.365323273340861 minutes
2024-09-16 19:21:57,860:INFO:SubProcess create_model() called ==================================
2024-09-16 19:21:57,860:INFO:Initializing create_model()
2024-09-16 19:21:57,860:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011727C2DF50>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011738687350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:21:57,860:INFO:Checking exceptions
2024-09-16 19:21:57,860:INFO:Importing libraries
2024-09-16 19:21:57,861:INFO:Copying training dataset
2024-09-16 19:21:57,868:INFO:Defining folds
2024-09-16 19:21:57,868:INFO:Declaring metric variables
2024-09-16 19:21:57,869:INFO:Importing untrained model
2024-09-16 19:21:57,869:INFO:Elastic Net Imported successfully
2024-09-16 19:21:57,869:INFO:Starting cross validation
2024-09-16 19:21:57,873:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:22:00,326:INFO:Calculating mean and std
2024-09-16 19:22:00,327:INFO:Creating metrics dataframe
2024-09-16 19:22:00,329:INFO:Uploading results into container
2024-09-16 19:22:00,330:INFO:Uploading model into container now
2024-09-16 19:22:00,330:INFO:_master_model_container: 4
2024-09-16 19:22:00,330:INFO:_display_container: 2
2024-09-16 19:22:00,331:INFO:ElasticNet(random_state=123)
2024-09-16 19:22:00,331:INFO:create_model() successfully completed......................................
2024-09-16 19:22:00,413:INFO:SubProcess create_model() end ==================================
2024-09-16 19:22:00,413:INFO:Creating metrics dataframe
2024-09-16 19:22:00,417:INFO:Initializing Least Angle Regression
2024-09-16 19:22:00,418:INFO:Total runtime is 0.4079693873723348 minutes
2024-09-16 19:22:00,418:INFO:SubProcess create_model() called ==================================
2024-09-16 19:22:00,418:INFO:Initializing create_model()
2024-09-16 19:22:00,418:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011727C2DF50>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011738687350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:22:00,418:INFO:Checking exceptions
2024-09-16 19:22:00,418:INFO:Importing libraries
2024-09-16 19:22:00,418:INFO:Copying training dataset
2024-09-16 19:22:00,426:INFO:Defining folds
2024-09-16 19:22:00,426:INFO:Declaring metric variables
2024-09-16 19:22:00,426:INFO:Importing untrained model
2024-09-16 19:22:00,426:INFO:Least Angle Regression Imported successfully
2024-09-16 19:22:00,427:INFO:Starting cross validation
2024-09-16 19:22:00,431:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:22:01,066:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=5.117e+02, with an active set of 48 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,069:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=7.454e+02, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,071:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=4.506e+02, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,074:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=7.507e+02, with an active set of 51 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,075:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=7.938e+02, with an active set of 60 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,076:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=7.735e+02, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,077:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=7.398e+02, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,079:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=6.903e+02, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,081:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=6.115e+02, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,081:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 82 iterations, i.e. alpha=5.650e+02, with an active set of 69 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,090:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=8.438e+02, with an active set of 81 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,091:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=6.889e+02, with an active set of 81 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,091:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=5.678e+03, with an active set of 77 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,092:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=5.551e+03, with an active set of 78 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,092:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=6.766e+02, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,092:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=6.362e+02, with an active set of 83 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,093:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=5.884e+02, with an active set of 84 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,094:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=4.347e+02, with an active set of 85 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,095:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=3.550e+02, with an active set of 85 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,095:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=2.705e+03, with an active set of 91 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,096:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=2.184e+02, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,096:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=1.207e+02, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,096:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=1.709e+03, with an active set of 93 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,097:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=1.009e+03, with an active set of 93 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,097:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=4.657e+01, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,098:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=2.065e+01, with an active set of 87 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,099:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=1.377e+01, with an active set of 89 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,100:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=9.817e+00, with an active set of 89 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,101:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=1.119e+03, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,101:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=6.965e+00, with an active set of 90 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,101:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=6.700e+00, with an active set of 90 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,102:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=2.479e+00, with an active set of 90 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,115:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=4.405e+04, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,118:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=2.817e+04, with an active set of 91 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,120:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=4.569e+04, with an active set of 93 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,813:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=9.455e+02, with an active set of 44 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,834:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=9.048e+02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,839:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.101e+03, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,865:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=5.990e+02, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,888:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=1.805e+09, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,890:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=1.419e+09, with an active set of 91 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:01,892:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=4.235e+08, with an active set of 93 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:02,582:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=7.038e+03, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:02,729:INFO:Calculating mean and std
2024-09-16 19:22:02,730:INFO:Creating metrics dataframe
2024-09-16 19:22:02,732:INFO:Uploading results into container
2024-09-16 19:22:02,733:INFO:Uploading model into container now
2024-09-16 19:22:02,733:INFO:_master_model_container: 5
2024-09-16 19:22:02,734:INFO:_display_container: 2
2024-09-16 19:22:02,734:INFO:Lars(random_state=123)
2024-09-16 19:22:02,734:INFO:create_model() successfully completed......................................
2024-09-16 19:22:02,815:INFO:SubProcess create_model() end ==================================
2024-09-16 19:22:02,816:INFO:Creating metrics dataframe
2024-09-16 19:22:02,819:INFO:Initializing Lasso Least Angle Regression
2024-09-16 19:22:02,819:INFO:Total runtime is 0.44798097213109334 minutes
2024-09-16 19:22:02,819:INFO:SubProcess create_model() called ==================================
2024-09-16 19:22:02,819:INFO:Initializing create_model()
2024-09-16 19:22:02,819:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011727C2DF50>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011738687350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:22:02,819:INFO:Checking exceptions
2024-09-16 19:22:02,820:INFO:Importing libraries
2024-09-16 19:22:02,820:INFO:Copying training dataset
2024-09-16 19:22:02,826:INFO:Defining folds
2024-09-16 19:22:02,827:INFO:Declaring metric variables
2024-09-16 19:22:02,827:INFO:Importing untrained model
2024-09-16 19:22:02,827:INFO:Lasso Least Angle Regression Imported successfully
2024-09-16 19:22:02,828:INFO:Starting cross validation
2024-09-16 19:22:02,831:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:22:03,446:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=1.435e+02, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:03,447:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=1.180e+02, with an active set of 60 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:03,453:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 82 iterations, alpha=9.372e+01, previous alpha=7.755e+01, with an active set of 73 regressors.
  warnings.warn(

2024-09-16 19:22:03,488:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=3.070e+01, with an active set of 75 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:03,494:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 98 iterations, alpha=1.535e+01, previous alpha=1.535e+01, with an active set of 81 regressors.
  warnings.warn(

2024-09-16 19:22:03,503:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 108 iterations, alpha=2.212e+00, previous alpha=2.212e+00, with an active set of 81 regressors.
  warnings.warn(

2024-09-16 19:22:04,289:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 102 iterations, alpha=9.960e+00, previous alpha=5.387e+00, with an active set of 79 regressors.
  warnings.warn(

2024-09-16 19:22:04,332:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=1.548e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:04,333:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=1.044e+01, with an active set of 77 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:04,340:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 108 iterations, alpha=5.444e+00, previous alpha=5.444e+00, with an active set of 79 regressors.
  warnings.warn(

2024-09-16 19:22:04,345:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=2.452e+01, with an active set of 75 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:04,350:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 101 iterations, alpha=1.817e+01, previous alpha=1.817e+01, with an active set of 76 regressors.
  warnings.warn(

2024-09-16 19:22:04,867:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=2.071e+02, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:04,868:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=1.952e+02, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:04,869:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=1.306e+02, with an active set of 61 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:22:04,870:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 68 iterations, alpha=1.363e+02, previous alpha=1.306e+02, with an active set of 61 regressors.
  warnings.warn(

2024-09-16 19:22:04,923:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 99 iterations, alpha=2.537e+01, previous alpha=2.533e+01, with an active set of 78 regressors.
  warnings.warn(

2024-09-16 19:22:05,007:INFO:Calculating mean and std
2024-09-16 19:22:05,008:INFO:Creating metrics dataframe
2024-09-16 19:22:05,010:INFO:Uploading results into container
2024-09-16 19:22:05,011:INFO:Uploading model into container now
2024-09-16 19:22:05,011:INFO:_master_model_container: 6
2024-09-16 19:22:05,011:INFO:_display_container: 2
2024-09-16 19:22:05,012:INFO:LassoLars(random_state=123)
2024-09-16 19:22:05,012:INFO:create_model() successfully completed......................................
2024-09-16 19:22:05,097:INFO:SubProcess create_model() end ==================================
2024-09-16 19:22:05,097:INFO:Creating metrics dataframe
2024-09-16 19:22:05,101:INFO:Initializing Orthogonal Matching Pursuit
2024-09-16 19:22:05,101:INFO:Total runtime is 0.4860109051068624 minutes
2024-09-16 19:22:05,101:INFO:SubProcess create_model() called ==================================
2024-09-16 19:22:05,102:INFO:Initializing create_model()
2024-09-16 19:22:05,102:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011727C2DF50>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011738687350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:22:05,102:INFO:Checking exceptions
2024-09-16 19:22:05,102:INFO:Importing libraries
2024-09-16 19:22:05,102:INFO:Copying training dataset
2024-09-16 19:22:05,109:INFO:Defining folds
2024-09-16 19:22:05,110:INFO:Declaring metric variables
2024-09-16 19:22:05,110:INFO:Importing untrained model
2024-09-16 19:22:05,110:INFO:Orthogonal Matching Pursuit Imported successfully
2024-09-16 19:22:05,110:INFO:Starting cross validation
2024-09-16 19:22:05,114:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:22:07,372:INFO:Calculating mean and std
2024-09-16 19:22:07,373:INFO:Creating metrics dataframe
2024-09-16 19:22:07,375:INFO:Uploading results into container
2024-09-16 19:22:07,376:INFO:Uploading model into container now
2024-09-16 19:22:07,376:INFO:_master_model_container: 7
2024-09-16 19:22:07,377:INFO:_display_container: 2
2024-09-16 19:22:07,377:INFO:OrthogonalMatchingPursuit()
2024-09-16 19:22:07,377:INFO:create_model() successfully completed......................................
2024-09-16 19:22:07,460:INFO:SubProcess create_model() end ==================================
2024-09-16 19:22:07,460:INFO:Creating metrics dataframe
2024-09-16 19:22:07,463:INFO:Initializing Bayesian Ridge
2024-09-16 19:22:07,463:INFO:Total runtime is 0.5253769159317017 minutes
2024-09-16 19:22:07,463:INFO:SubProcess create_model() called ==================================
2024-09-16 19:22:07,464:INFO:Initializing create_model()
2024-09-16 19:22:07,464:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011727C2DF50>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011738687350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:22:07,464:INFO:Checking exceptions
2024-09-16 19:22:07,464:INFO:Importing libraries
2024-09-16 19:22:07,464:INFO:Copying training dataset
2024-09-16 19:22:07,472:INFO:Defining folds
2024-09-16 19:22:07,472:INFO:Declaring metric variables
2024-09-16 19:22:07,472:INFO:Importing untrained model
2024-09-16 19:22:07,472:INFO:Bayesian Ridge Imported successfully
2024-09-16 19:22:07,473:INFO:Starting cross validation
2024-09-16 19:22:07,476:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:22:10,172:INFO:Calculating mean and std
2024-09-16 19:22:10,173:INFO:Creating metrics dataframe
2024-09-16 19:22:10,175:INFO:Uploading results into container
2024-09-16 19:22:10,176:INFO:Uploading model into container now
2024-09-16 19:22:10,177:INFO:_master_model_container: 8
2024-09-16 19:22:10,177:INFO:_display_container: 2
2024-09-16 19:22:10,177:INFO:BayesianRidge()
2024-09-16 19:22:10,177:INFO:create_model() successfully completed......................................
2024-09-16 19:22:10,259:INFO:SubProcess create_model() end ==================================
2024-09-16 19:22:10,260:INFO:Creating metrics dataframe
2024-09-16 19:22:10,263:INFO:Initializing Passive Aggressive Regressor
2024-09-16 19:22:10,263:INFO:Total runtime is 0.5720531304677328 minutes
2024-09-16 19:22:10,263:INFO:SubProcess create_model() called ==================================
2024-09-16 19:22:10,264:INFO:Initializing create_model()
2024-09-16 19:22:10,264:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011727C2DF50>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011738687350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:22:10,264:INFO:Checking exceptions
2024-09-16 19:22:10,264:INFO:Importing libraries
2024-09-16 19:22:10,264:INFO:Copying training dataset
2024-09-16 19:22:10,271:INFO:Defining folds
2024-09-16 19:22:10,271:INFO:Declaring metric variables
2024-09-16 19:22:10,271:INFO:Importing untrained model
2024-09-16 19:22:10,272:INFO:Passive Aggressive Regressor Imported successfully
2024-09-16 19:22:10,272:INFO:Starting cross validation
2024-09-16 19:22:10,275:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:22:12,415:INFO:Calculating mean and std
2024-09-16 19:22:12,416:INFO:Creating metrics dataframe
2024-09-16 19:22:12,418:INFO:Uploading results into container
2024-09-16 19:22:12,419:INFO:Uploading model into container now
2024-09-16 19:22:12,419:INFO:_master_model_container: 9
2024-09-16 19:22:12,419:INFO:_display_container: 2
2024-09-16 19:22:12,420:INFO:PassiveAggressiveRegressor(random_state=123)
2024-09-16 19:22:12,420:INFO:create_model() successfully completed......................................
2024-09-16 19:22:12,501:INFO:SubProcess create_model() end ==================================
2024-09-16 19:22:12,501:INFO:Creating metrics dataframe
2024-09-16 19:22:12,504:INFO:Initializing Huber Regressor
2024-09-16 19:22:12,505:INFO:Total runtime is 0.609409240881602 minutes
2024-09-16 19:22:12,505:INFO:SubProcess create_model() called ==================================
2024-09-16 19:22:12,505:INFO:Initializing create_model()
2024-09-16 19:22:12,505:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011727C2DF50>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011738687350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:22:12,505:INFO:Checking exceptions
2024-09-16 19:22:12,505:INFO:Importing libraries
2024-09-16 19:22:12,505:INFO:Copying training dataset
2024-09-16 19:22:12,513:INFO:Defining folds
2024-09-16 19:22:12,513:INFO:Declaring metric variables
2024-09-16 19:22:12,513:INFO:Importing untrained model
2024-09-16 19:22:12,513:INFO:Huber Regressor Imported successfully
2024-09-16 19:22:12,514:INFO:Starting cross validation
2024-09-16 19:22:12,517:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:22:15,792:INFO:Calculating mean and std
2024-09-16 19:22:15,793:INFO:Creating metrics dataframe
2024-09-16 19:22:15,795:INFO:Uploading results into container
2024-09-16 19:22:15,796:INFO:Uploading model into container now
2024-09-16 19:22:15,796:INFO:_master_model_container: 10
2024-09-16 19:22:15,796:INFO:_display_container: 2
2024-09-16 19:22:15,797:INFO:HuberRegressor()
2024-09-16 19:22:15,797:INFO:create_model() successfully completed......................................
2024-09-16 19:22:15,879:INFO:SubProcess create_model() end ==================================
2024-09-16 19:22:15,879:INFO:Creating metrics dataframe
2024-09-16 19:22:15,883:INFO:Initializing K Neighbors Regressor
2024-09-16 19:22:15,883:INFO:Total runtime is 0.6657101551691691 minutes
2024-09-16 19:22:15,883:INFO:SubProcess create_model() called ==================================
2024-09-16 19:22:15,883:INFO:Initializing create_model()
2024-09-16 19:22:15,883:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011727C2DF50>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011738687350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:22:15,883:INFO:Checking exceptions
2024-09-16 19:22:15,883:INFO:Importing libraries
2024-09-16 19:22:15,884:INFO:Copying training dataset
2024-09-16 19:22:15,890:INFO:Defining folds
2024-09-16 19:22:15,890:INFO:Declaring metric variables
2024-09-16 19:22:15,891:INFO:Importing untrained model
2024-09-16 19:22:15,891:INFO:K Neighbors Regressor Imported successfully
2024-09-16 19:22:15,891:INFO:Starting cross validation
2024-09-16 19:22:15,895:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:22:18,906:INFO:Calculating mean and std
2024-09-16 19:22:18,908:INFO:Creating metrics dataframe
2024-09-16 19:22:18,910:INFO:Uploading results into container
2024-09-16 19:22:18,911:INFO:Uploading model into container now
2024-09-16 19:22:18,911:INFO:_master_model_container: 11
2024-09-16 19:22:18,911:INFO:_display_container: 2
2024-09-16 19:22:18,911:INFO:KNeighborsRegressor(n_jobs=-1)
2024-09-16 19:22:18,912:INFO:create_model() successfully completed......................................
2024-09-16 19:22:19,003:INFO:SubProcess create_model() end ==================================
2024-09-16 19:22:19,003:INFO:Creating metrics dataframe
2024-09-16 19:22:19,006:INFO:Initializing Decision Tree Regressor
2024-09-16 19:22:19,007:INFO:Total runtime is 0.717779537041982 minutes
2024-09-16 19:22:19,007:INFO:SubProcess create_model() called ==================================
2024-09-16 19:22:19,007:INFO:Initializing create_model()
2024-09-16 19:22:19,007:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011727C2DF50>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011738687350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:22:19,007:INFO:Checking exceptions
2024-09-16 19:22:19,007:INFO:Importing libraries
2024-09-16 19:22:19,007:INFO:Copying training dataset
2024-09-16 19:22:19,015:INFO:Defining folds
2024-09-16 19:22:19,015:INFO:Declaring metric variables
2024-09-16 19:22:19,016:INFO:Importing untrained model
2024-09-16 19:22:19,016:INFO:Decision Tree Regressor Imported successfully
2024-09-16 19:22:19,017:INFO:Starting cross validation
2024-09-16 19:22:19,020:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:22:21,925:INFO:Calculating mean and std
2024-09-16 19:22:21,926:INFO:Creating metrics dataframe
2024-09-16 19:22:21,929:INFO:Uploading results into container
2024-09-16 19:22:21,930:INFO:Uploading model into container now
2024-09-16 19:22:21,931:INFO:_master_model_container: 12
2024-09-16 19:22:21,931:INFO:_display_container: 2
2024-09-16 19:22:21,931:INFO:DecisionTreeRegressor(random_state=123)
2024-09-16 19:22:21,931:INFO:create_model() successfully completed......................................
2024-09-16 19:22:22,024:INFO:SubProcess create_model() end ==================================
2024-09-16 19:22:22,024:INFO:Creating metrics dataframe
2024-09-16 19:22:22,030:INFO:Initializing Random Forest Regressor
2024-09-16 19:22:22,030:INFO:Total runtime is 0.7681739727656047 minutes
2024-09-16 19:22:22,030:INFO:SubProcess create_model() called ==================================
2024-09-16 19:22:22,031:INFO:Initializing create_model()
2024-09-16 19:22:22,031:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011727C2DF50>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011738687350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:22:22,031:INFO:Checking exceptions
2024-09-16 19:22:22,031:INFO:Importing libraries
2024-09-16 19:22:22,031:INFO:Copying training dataset
2024-09-16 19:22:22,045:INFO:Defining folds
2024-09-16 19:22:22,045:INFO:Declaring metric variables
2024-09-16 19:22:22,046:INFO:Importing untrained model
2024-09-16 19:22:22,046:INFO:Random Forest Regressor Imported successfully
2024-09-16 19:22:22,047:INFO:Starting cross validation
2024-09-16 19:22:22,054:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:22:58,431:INFO:Calculating mean and std
2024-09-16 19:22:58,432:INFO:Creating metrics dataframe
2024-09-16 19:22:58,435:INFO:Uploading results into container
2024-09-16 19:22:58,436:INFO:Uploading model into container now
2024-09-16 19:22:58,437:INFO:_master_model_container: 13
2024-09-16 19:22:58,437:INFO:_display_container: 2
2024-09-16 19:22:58,438:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-09-16 19:22:58,438:INFO:create_model() successfully completed......................................
2024-09-16 19:22:58,561:INFO:SubProcess create_model() end ==================================
2024-09-16 19:22:58,562:INFO:Creating metrics dataframe
2024-09-16 19:22:58,570:INFO:Initializing Extra Trees Regressor
2024-09-16 19:22:58,570:INFO:Total runtime is 1.3771714488665263 minutes
2024-09-16 19:22:58,570:INFO:SubProcess create_model() called ==================================
2024-09-16 19:22:58,571:INFO:Initializing create_model()
2024-09-16 19:22:58,571:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011727C2DF50>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011738687350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:22:58,571:INFO:Checking exceptions
2024-09-16 19:22:58,571:INFO:Importing libraries
2024-09-16 19:22:58,571:INFO:Copying training dataset
2024-09-16 19:22:58,585:INFO:Defining folds
2024-09-16 19:22:58,585:INFO:Declaring metric variables
2024-09-16 19:22:58,586:INFO:Importing untrained model
2024-09-16 19:22:58,586:INFO:Extra Trees Regressor Imported successfully
2024-09-16 19:22:58,587:INFO:Starting cross validation
2024-09-16 19:22:58,591:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:23:38,409:INFO:Calculating mean and std
2024-09-16 19:23:38,411:INFO:Creating metrics dataframe
2024-09-16 19:23:38,417:INFO:Uploading results into container
2024-09-16 19:23:38,418:INFO:Uploading model into container now
2024-09-16 19:23:38,419:INFO:_master_model_container: 14
2024-09-16 19:23:38,419:INFO:_display_container: 2
2024-09-16 19:23:38,420:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-09-16 19:23:38,420:INFO:create_model() successfully completed......................................
2024-09-16 19:23:38,568:INFO:SubProcess create_model() end ==================================
2024-09-16 19:23:38,568:INFO:Creating metrics dataframe
2024-09-16 19:23:38,576:INFO:Initializing AdaBoost Regressor
2024-09-16 19:23:38,576:INFO:Total runtime is 2.043927490711212 minutes
2024-09-16 19:23:38,576:INFO:SubProcess create_model() called ==================================
2024-09-16 19:23:38,577:INFO:Initializing create_model()
2024-09-16 19:23:38,577:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011727C2DF50>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011738687350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:23:38,577:INFO:Checking exceptions
2024-09-16 19:23:38,577:INFO:Importing libraries
2024-09-16 19:23:38,577:INFO:Copying training dataset
2024-09-16 19:23:38,599:INFO:Defining folds
2024-09-16 19:23:38,600:INFO:Declaring metric variables
2024-09-16 19:23:38,601:INFO:Importing untrained model
2024-09-16 19:23:38,601:INFO:AdaBoost Regressor Imported successfully
2024-09-16 19:23:38,602:INFO:Starting cross validation
2024-09-16 19:23:38,612:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:23:50,220:INFO:Calculating mean and std
2024-09-16 19:23:50,223:INFO:Creating metrics dataframe
2024-09-16 19:23:50,227:INFO:Uploading results into container
2024-09-16 19:23:50,229:INFO:Uploading model into container now
2024-09-16 19:23:50,230:INFO:_master_model_container: 15
2024-09-16 19:23:50,230:INFO:_display_container: 2
2024-09-16 19:23:50,230:INFO:AdaBoostRegressor(random_state=123)
2024-09-16 19:23:50,231:INFO:create_model() successfully completed......................................
2024-09-16 19:23:50,346:INFO:SubProcess create_model() end ==================================
2024-09-16 19:23:50,347:INFO:Creating metrics dataframe
2024-09-16 19:23:50,352:INFO:Initializing Gradient Boosting Regressor
2024-09-16 19:23:50,352:INFO:Total runtime is 2.2401975870132445 minutes
2024-09-16 19:23:50,353:INFO:SubProcess create_model() called ==================================
2024-09-16 19:23:50,353:INFO:Initializing create_model()
2024-09-16 19:23:50,353:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011727C2DF50>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011738687350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:23:50,353:INFO:Checking exceptions
2024-09-16 19:23:50,353:INFO:Importing libraries
2024-09-16 19:23:50,354:INFO:Copying training dataset
2024-09-16 19:23:50,367:INFO:Defining folds
2024-09-16 19:23:50,367:INFO:Declaring metric variables
2024-09-16 19:23:50,367:INFO:Importing untrained model
2024-09-16 19:23:50,368:INFO:Gradient Boosting Regressor Imported successfully
2024-09-16 19:23:50,369:INFO:Starting cross validation
2024-09-16 19:23:50,376:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:23:59,893:INFO:Calculating mean and std
2024-09-16 19:23:59,895:INFO:Creating metrics dataframe
2024-09-16 19:23:59,898:INFO:Uploading results into container
2024-09-16 19:23:59,899:INFO:Uploading model into container now
2024-09-16 19:23:59,899:INFO:_master_model_container: 16
2024-09-16 19:23:59,899:INFO:_display_container: 2
2024-09-16 19:23:59,900:INFO:GradientBoostingRegressor(random_state=123)
2024-09-16 19:23:59,900:INFO:create_model() successfully completed......................................
2024-09-16 19:23:59,998:INFO:SubProcess create_model() end ==================================
2024-09-16 19:23:59,998:INFO:Creating metrics dataframe
2024-09-16 19:24:00,002:INFO:Initializing Light Gradient Boosting Machine
2024-09-16 19:24:00,002:INFO:Total runtime is 2.4010309855143226 minutes
2024-09-16 19:24:00,003:INFO:SubProcess create_model() called ==================================
2024-09-16 19:24:00,003:INFO:Initializing create_model()
2024-09-16 19:24:00,003:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011727C2DF50>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011738687350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:24:00,003:INFO:Checking exceptions
2024-09-16 19:24:00,003:INFO:Importing libraries
2024-09-16 19:24:00,003:INFO:Copying training dataset
2024-09-16 19:24:00,017:INFO:Defining folds
2024-09-16 19:24:00,018:INFO:Declaring metric variables
2024-09-16 19:24:00,018:INFO:Importing untrained model
2024-09-16 19:24:00,019:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-16 19:24:00,019:INFO:Starting cross validation
2024-09-16 19:24:00,025:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:24:03,954:INFO:Calculating mean and std
2024-09-16 19:24:03,956:INFO:Creating metrics dataframe
2024-09-16 19:24:03,959:INFO:Uploading results into container
2024-09-16 19:24:03,961:INFO:Uploading model into container now
2024-09-16 19:24:03,962:INFO:_master_model_container: 17
2024-09-16 19:24:03,962:INFO:_display_container: 2
2024-09-16 19:24:03,963:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-09-16 19:24:03,963:INFO:create_model() successfully completed......................................
2024-09-16 19:24:04,119:INFO:SubProcess create_model() end ==================================
2024-09-16 19:24:04,119:INFO:Creating metrics dataframe
2024-09-16 19:24:04,124:INFO:Initializing Dummy Regressor
2024-09-16 19:24:04,124:INFO:Total runtime is 2.469741523265838 minutes
2024-09-16 19:24:04,124:INFO:SubProcess create_model() called ==================================
2024-09-16 19:24:04,125:INFO:Initializing create_model()
2024-09-16 19:24:04,125:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011727C2DF50>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000011738687350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:24:04,125:INFO:Checking exceptions
2024-09-16 19:24:04,125:INFO:Importing libraries
2024-09-16 19:24:04,125:INFO:Copying training dataset
2024-09-16 19:24:04,141:INFO:Defining folds
2024-09-16 19:24:04,141:INFO:Declaring metric variables
2024-09-16 19:24:04,142:INFO:Importing untrained model
2024-09-16 19:24:04,142:INFO:Dummy Regressor Imported successfully
2024-09-16 19:24:04,143:INFO:Starting cross validation
2024-09-16 19:24:04,152:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:24:06,715:INFO:Calculating mean and std
2024-09-16 19:24:06,716:INFO:Creating metrics dataframe
2024-09-16 19:24:06,719:INFO:Uploading results into container
2024-09-16 19:24:06,719:INFO:Uploading model into container now
2024-09-16 19:24:06,720:INFO:_master_model_container: 18
2024-09-16 19:24:06,720:INFO:_display_container: 2
2024-09-16 19:24:06,720:INFO:DummyRegressor()
2024-09-16 19:24:06,720:INFO:create_model() successfully completed......................................
2024-09-16 19:24:06,815:INFO:SubProcess create_model() end ==================================
2024-09-16 19:24:06,816:INFO:Creating metrics dataframe
2024-09-16 19:24:06,825:WARNING:D:\grad-proj\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-09-16 19:24:06,827:INFO:Initializing create_model()
2024-09-16 19:24:06,828:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000011727C2DF50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:24:06,828:INFO:Checking exceptions
2024-09-16 19:24:06,829:INFO:Importing libraries
2024-09-16 19:24:06,829:INFO:Copying training dataset
2024-09-16 19:24:06,838:INFO:Defining folds
2024-09-16 19:24:06,838:INFO:Declaring metric variables
2024-09-16 19:24:06,839:INFO:Importing untrained model
2024-09-16 19:24:06,839:INFO:Declaring custom model
2024-09-16 19:24:06,840:INFO:Random Forest Regressor Imported successfully
2024-09-16 19:24:06,843:INFO:Cross validation set to False
2024-09-16 19:24:06,843:INFO:Fitting Model
2024-09-16 19:24:10,792:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-09-16 19:24:10,793:INFO:create_model() successfully completed......................................
2024-09-16 19:24:10,961:INFO:_master_model_container: 18
2024-09-16 19:24:10,961:INFO:_display_container: 2
2024-09-16 19:24:10,962:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-09-16 19:24:10,962:INFO:compare_models() successfully completed......................................
2024-09-16 19:24:10,978:INFO:Initializing save_model()
2024-09-16 19:24:10,978:INFO:save_model(model=RandomForestRegressor(n_jobs=-1, random_state=123), model_name=D:\Grad-proj\ML\my_model_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Dell\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['long', 'lat', 'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['city', 'neighborhood',
                                             'subcategory', 'facade',
                                             'payment_method', 'bedrooms',
                                             'bathrooms', 'furnished', 'floor',
                                             'building_...
                                             'bathrooms', 'furnished', 'floor',
                                             'building_age'],
                                    transformer=OneHotEncoder(cols=['city',
                                                                    'subcategory',
                                                                    'facade',
                                                                    'payment_method',
                                                                    'bedrooms',
                                                                    'bathrooms',
                                                                    'furnished',
                                                                    'floor',
                                                                    'building_age'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['neighborhood'],
                                    transformer=TargetEncoder(cols=['neighborhood'],
                                                              handle_missing='return_nan')))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2024-09-16 19:24:10,978:INFO:Adding model into prep_pipe
2024-09-16 19:24:11,080:INFO:D:\Grad-proj\ML\my_model_pipeline.pkl saved in current working directory
2024-09-16 19:24:11,096:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['long', 'lat', 'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['city', 'neighborhood',
                                             'subcategory', 'facade',
                                             'payment_method', 'bedrooms',
                                             'bathrooms', 'furnished', 'floor',
                                             'building_age'],
                                    transformer=SimpleImputer(strateg...
                                                                    'subcategory',
                                                                    'facade',
                                                                    'payment_method',
                                                                    'bedrooms',
                                                                    'bathrooms',
                                                                    'furnished',
                                                                    'floor',
                                                                    'building_age'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['neighborhood'],
                                    transformer=TargetEncoder(cols=['neighborhood'],
                                                              handle_missing='return_nan'))),
                ('trained_model',
                 RandomForestRegressor(n_jobs=-1, random_state=123))])
2024-09-16 19:24:11,097:INFO:save_model() successfully completed......................................
2024-09-16 19:24:11,209:INFO:Initializing load_model()
2024-09-16 19:24:11,211:INFO:load_model(model_name=D:/Grad-proj/ML/my_model_pipeline, platform=None, authentication=None, verbose=True)
2024-09-16 19:34:08,820:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-16 19:34:08,820:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-16 19:34:08,820:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-16 19:34:08,820:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-16 19:34:09,683:INFO:PyCaret RegressionExperiment
2024-09-16 19:34:09,683:INFO:Logging name: reg-default-name
2024-09-16 19:34:09,683:INFO:ML Usecase: MLUsecase.REGRESSION
2024-09-16 19:34:09,683:INFO:version 3.3.2
2024-09-16 19:34:09,683:INFO:Initializing setup()
2024-09-16 19:34:09,683:INFO:self.USI: f28c
2024-09-16 19:34:09,683:INFO:self._variable_keys: {'pipeline', 'fold_generator', 'idx', 'gpu_param', 'exp_name_log', 'y_train', 'USI', 'html_param', 'X_test', 'log_plots_param', 'X_train', 'X', 'exp_id', 'data', '_available_plots', 'fold_groups_param', 'seed', 'logging_param', 'memory', 'y_test', 'y', 'gpu_n_jobs_param', '_ml_usecase', 'fold_shuffle_param', 'target_param', 'transform_target_param', 'n_jobs_param'}
2024-09-16 19:34:09,683:INFO:Checking environment
2024-09-16 19:34:09,683:INFO:python_version: 3.11.3
2024-09-16 19:34:09,683:INFO:python_build: ('tags/v3.11.3:f3909b8', 'Apr  4 2023 23:49:59')
2024-09-16 19:34:09,683:INFO:machine: AMD64
2024-09-16 19:34:09,699:INFO:platform: Windows-10-10.0.19045-SP0
2024-09-16 19:34:09,702:INFO:Memory: svmem(total=8459001856, available=2027479040, percent=76.0, used=6431522816, free=2027479040)
2024-09-16 19:34:09,702:INFO:Physical Core: 2
2024-09-16 19:34:09,702:INFO:Logical Core: 4
2024-09-16 19:34:09,702:INFO:Checking libraries
2024-09-16 19:34:09,702:INFO:System:
2024-09-16 19:34:09,702:INFO:    python: 3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]
2024-09-16 19:34:09,702:INFO:executable: D:\grad-proj\Scripts\python.exe
2024-09-16 19:34:09,702:INFO:   machine: Windows-10-10.0.19045-SP0
2024-09-16 19:34:09,702:INFO:PyCaret required dependencies:
2024-09-16 19:34:09,761:INFO:                 pip: 22.3.1
2024-09-16 19:34:09,761:INFO:          setuptools: 65.5.0
2024-09-16 19:34:09,761:INFO:             pycaret: 3.3.2
2024-09-16 19:34:09,761:INFO:             IPython: 8.27.0
2024-09-16 19:34:09,761:INFO:          ipywidgets: 8.1.5
2024-09-16 19:34:09,761:INFO:                tqdm: 4.66.5
2024-09-16 19:34:09,761:INFO:               numpy: 1.26.4
2024-09-16 19:34:09,761:INFO:              pandas: 2.1.4
2024-09-16 19:34:09,761:INFO:              jinja2: 3.1.4
2024-09-16 19:34:09,761:INFO:               scipy: 1.11.4
2024-09-16 19:34:09,761:INFO:              joblib: 1.3.2
2024-09-16 19:34:09,761:INFO:             sklearn: 1.4.2
2024-09-16 19:34:09,761:INFO:                pyod: 2.0.2
2024-09-16 19:34:09,761:INFO:            imblearn: 0.12.3
2024-09-16 19:34:09,761:INFO:   category_encoders: 2.6.3
2024-09-16 19:34:09,761:INFO:            lightgbm: 4.5.0
2024-09-16 19:34:09,762:INFO:               numba: 0.60.0
2024-09-16 19:34:09,762:INFO:            requests: 2.32.3
2024-09-16 19:34:09,762:INFO:          matplotlib: 3.7.5
2024-09-16 19:34:09,762:INFO:          scikitplot: 0.3.7
2024-09-16 19:34:09,762:INFO:         yellowbrick: 1.5
2024-09-16 19:34:09,762:INFO:              plotly: 5.24.1
2024-09-16 19:34:09,762:INFO:    plotly-resampler: Not installed
2024-09-16 19:34:09,762:INFO:             kaleido: 0.2.1
2024-09-16 19:34:09,762:INFO:           schemdraw: 0.15
2024-09-16 19:34:09,762:INFO:         statsmodels: 0.14.3
2024-09-16 19:34:09,762:INFO:              sktime: 0.26.0
2024-09-16 19:34:09,762:INFO:               tbats: 1.1.3
2024-09-16 19:34:09,762:INFO:            pmdarima: 2.0.4
2024-09-16 19:34:09,762:INFO:              psutil: 6.0.0
2024-09-16 19:34:09,762:INFO:          markupsafe: 2.1.5
2024-09-16 19:34:09,762:INFO:             pickle5: Not installed
2024-09-16 19:34:09,762:INFO:         cloudpickle: 3.0.0
2024-09-16 19:34:09,762:INFO:         deprecation: 2.1.0
2024-09-16 19:34:09,762:INFO:              xxhash: 3.5.0
2024-09-16 19:34:09,763:INFO:           wurlitzer: Not installed
2024-09-16 19:34:09,763:INFO:PyCaret optional dependencies:
2024-09-16 19:34:09,805:INFO:                shap: Not installed
2024-09-16 19:34:09,805:INFO:           interpret: Not installed
2024-09-16 19:34:09,805:INFO:                umap: Not installed
2024-09-16 19:34:09,805:INFO:     ydata_profiling: Not installed
2024-09-16 19:34:09,805:INFO:  explainerdashboard: Not installed
2024-09-16 19:34:09,806:INFO:             autoviz: Not installed
2024-09-16 19:34:09,806:INFO:           fairlearn: Not installed
2024-09-16 19:34:09,806:INFO:          deepchecks: Not installed
2024-09-16 19:34:09,806:INFO:             xgboost: Not installed
2024-09-16 19:34:09,806:INFO:            catboost: Not installed
2024-09-16 19:34:09,806:INFO:              kmodes: Not installed
2024-09-16 19:34:09,806:INFO:             mlxtend: Not installed
2024-09-16 19:34:09,806:INFO:       statsforecast: Not installed
2024-09-16 19:34:09,806:INFO:        tune_sklearn: Not installed
2024-09-16 19:34:09,806:INFO:                 ray: Not installed
2024-09-16 19:34:09,806:INFO:            hyperopt: Not installed
2024-09-16 19:34:09,806:INFO:              optuna: Not installed
2024-09-16 19:34:09,806:INFO:               skopt: Not installed
2024-09-16 19:34:09,806:INFO:              mlflow: Not installed
2024-09-16 19:34:09,806:INFO:              gradio: Not installed
2024-09-16 19:34:09,806:INFO:             fastapi: Not installed
2024-09-16 19:34:09,806:INFO:             uvicorn: Not installed
2024-09-16 19:34:09,806:INFO:              m2cgen: Not installed
2024-09-16 19:34:09,807:INFO:           evidently: Not installed
2024-09-16 19:34:09,807:INFO:               fugue: Not installed
2024-09-16 19:34:09,807:INFO:           streamlit: Not installed
2024-09-16 19:34:09,807:INFO:             prophet: Not installed
2024-09-16 19:34:09,807:INFO:None
2024-09-16 19:34:09,807:INFO:Set up data.
2024-09-16 19:34:09,843:INFO:Set up folding strategy.
2024-09-16 19:34:09,844:INFO:Set up train/test split.
2024-09-16 19:34:09,857:INFO:Set up index.
2024-09-16 19:34:09,858:INFO:Assigning column types.
2024-09-16 19:34:09,866:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-16 19:34:09,866:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-09-16 19:34:09,873:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-09-16 19:34:09,880:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-09-16 19:34:09,986:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 19:34:10,043:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-16 19:34:10,045:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:34:10,045:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:34:10,046:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-09-16 19:34:10,051:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-09-16 19:34:10,057:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-09-16 19:34:10,132:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 19:34:10,184:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-16 19:34:10,185:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:34:10,185:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:34:10,185:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-09-16 19:34:10,191:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-09-16 19:34:10,196:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-09-16 19:34:10,269:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 19:34:10,322:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-16 19:34:10,323:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:34:10,323:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:34:10,329:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-09-16 19:34:10,336:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-09-16 19:34:10,418:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 19:34:10,476:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-16 19:34:10,476:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:34:10,477:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:34:10,477:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-09-16 19:34:10,490:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-09-16 19:34:10,571:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 19:34:10,630:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-16 19:34:10,631:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:34:10,632:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:34:10,644:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-09-16 19:34:10,730:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 19:34:10,792:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-16 19:34:10,793:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:34:10,793:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:34:10,794:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-09-16 19:34:10,877:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 19:34:10,930:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-16 19:34:10,930:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:34:10,931:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:34:11,014:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 19:34:11,070:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-16 19:34:11,072:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:34:11,072:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:34:11,072:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-16 19:34:11,164:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 19:34:11,224:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:34:11,224:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:34:11,312:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-09-16 19:34:11,388:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:34:11,388:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:34:11,389:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-09-16 19:34:11,532:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:34:11,532:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:34:11,673:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:34:11,673:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:34:11,677:INFO:Preparing preprocessing pipeline...
2024-09-16 19:34:11,678:INFO:Set up simple imputation.
2024-09-16 19:34:11,683:INFO:Set up encoding of categorical features.
2024-09-16 19:34:11,887:INFO:Finished creating preprocessing pipeline.
2024-09-16 19:34:11,903:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Dell\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['long', 'lat', 'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['city', 'neighborhood',
                                             'subcategory', 'facade',
                                             'payment_method', 'bedrooms',
                                             'bathrooms', 'furnished', 'floor',
                                             'building_...
                                             'bathrooms', 'furnished', 'floor',
                                             'building_age'],
                                    transformer=OneHotEncoder(cols=['city',
                                                                    'subcategory',
                                                                    'facade',
                                                                    'payment_method',
                                                                    'bedrooms',
                                                                    'bathrooms',
                                                                    'furnished',
                                                                    'floor',
                                                                    'building_age'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['neighborhood'],
                                    transformer=TargetEncoder(cols=['neighborhood'],
                                                              handle_missing='return_nan')))])
2024-09-16 19:34:11,903:INFO:Creating final display dataframe.
2024-09-16 19:34:12,144:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             price
2                   Target type        Regression
3           Original data shape        (8513, 14)
4        Transformed data shape        (8513, 96)
5   Transformed train set shape        (5959, 96)
6    Transformed test set shape        (2554, 96)
7              Numeric features                 3
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              f28c
2024-09-16 19:34:12,315:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:34:12,315:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:34:12,459:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:34:12,459:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-09-16 19:34:12,460:INFO:setup() successfully completed in 2.79s...............
2024-09-16 19:34:12,460:INFO:Initializing compare_models()
2024-09-16 19:34:12,460:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016C7A30E250>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000016C7A30E250>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2024-09-16 19:34:12,460:INFO:Checking exceptions
2024-09-16 19:34:12,463:INFO:Preparing display monitor
2024-09-16 19:34:12,466:INFO:Initializing Linear Regression
2024-09-16 19:34:12,467:INFO:Total runtime is 0.0 minutes
2024-09-16 19:34:12,467:INFO:SubProcess create_model() called ==================================
2024-09-16 19:34:12,467:INFO:Initializing create_model()
2024-09-16 19:34:12,467:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016C7A30E250>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016C0AEABB90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:34:12,467:INFO:Checking exceptions
2024-09-16 19:34:12,467:INFO:Importing libraries
2024-09-16 19:34:12,467:INFO:Copying training dataset
2024-09-16 19:34:12,475:INFO:Defining folds
2024-09-16 19:34:12,475:INFO:Declaring metric variables
2024-09-16 19:34:12,475:INFO:Importing untrained model
2024-09-16 19:34:12,476:INFO:Linear Regression Imported successfully
2024-09-16 19:34:12,476:INFO:Starting cross validation
2024-09-16 19:34:12,492:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:34:24,491:INFO:Calculating mean and std
2024-09-16 19:34:24,492:INFO:Creating metrics dataframe
2024-09-16 19:34:24,497:INFO:Uploading results into container
2024-09-16 19:34:24,498:INFO:Uploading model into container now
2024-09-16 19:34:24,499:INFO:_master_model_container: 1
2024-09-16 19:34:24,499:INFO:_display_container: 2
2024-09-16 19:34:24,501:INFO:LinearRegression(n_jobs=-1)
2024-09-16 19:34:24,501:INFO:create_model() successfully completed......................................
2024-09-16 19:34:24,633:INFO:SubProcess create_model() end ==================================
2024-09-16 19:34:24,633:INFO:Creating metrics dataframe
2024-09-16 19:34:24,638:INFO:Initializing Lasso Regression
2024-09-16 19:34:24,638:INFO:Total runtime is 0.20286755164464315 minutes
2024-09-16 19:34:24,639:INFO:SubProcess create_model() called ==================================
2024-09-16 19:34:24,639:INFO:Initializing create_model()
2024-09-16 19:34:24,639:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016C7A30E250>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016C0AEABB90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:34:24,639:INFO:Checking exceptions
2024-09-16 19:34:24,639:INFO:Importing libraries
2024-09-16 19:34:24,640:INFO:Copying training dataset
2024-09-16 19:34:24,653:INFO:Defining folds
2024-09-16 19:34:24,654:INFO:Declaring metric variables
2024-09-16 19:34:24,654:INFO:Importing untrained model
2024-09-16 19:34:24,655:INFO:Lasso Regression Imported successfully
2024-09-16 19:34:24,655:INFO:Starting cross validation
2024-09-16 19:34:24,663:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:34:27,376:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.137e+14, tolerance: 1.323e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 19:34:27,377:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.188e+14, tolerance: 1.331e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 19:34:27,414:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.201e+14, tolerance: 1.340e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 19:34:27,506:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.294e+14, tolerance: 1.117e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 19:34:30,043:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.255e+14, tolerance: 1.343e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 19:34:30,068:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.306e+14, tolerance: 9.170e+10
  model = cd_fast.enet_coordinate_descent(

2024-09-16 19:34:30,204:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.939e+14, tolerance: 1.272e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 19:34:30,318:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.035e+14, tolerance: 1.303e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 19:34:31,998:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.888e+14, tolerance: 1.268e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 19:34:32,005:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.022e+14, tolerance: 1.288e+11
  model = cd_fast.enet_coordinate_descent(

2024-09-16 19:34:32,090:INFO:Calculating mean and std
2024-09-16 19:34:32,091:INFO:Creating metrics dataframe
2024-09-16 19:34:32,094:INFO:Uploading results into container
2024-09-16 19:34:32,094:INFO:Uploading model into container now
2024-09-16 19:34:32,095:INFO:_master_model_container: 2
2024-09-16 19:34:32,095:INFO:_display_container: 2
2024-09-16 19:34:32,095:INFO:Lasso(random_state=123)
2024-09-16 19:34:32,095:INFO:create_model() successfully completed......................................
2024-09-16 19:34:32,178:INFO:SubProcess create_model() end ==================================
2024-09-16 19:34:32,178:INFO:Creating metrics dataframe
2024-09-16 19:34:32,181:INFO:Initializing Ridge Regression
2024-09-16 19:34:32,181:INFO:Total runtime is 0.32859388589859007 minutes
2024-09-16 19:34:32,182:INFO:SubProcess create_model() called ==================================
2024-09-16 19:34:32,182:INFO:Initializing create_model()
2024-09-16 19:34:32,182:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016C7A30E250>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016C0AEABB90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:34:32,182:INFO:Checking exceptions
2024-09-16 19:34:32,182:INFO:Importing libraries
2024-09-16 19:34:32,182:INFO:Copying training dataset
2024-09-16 19:34:32,189:INFO:Defining folds
2024-09-16 19:34:32,189:INFO:Declaring metric variables
2024-09-16 19:34:32,190:INFO:Importing untrained model
2024-09-16 19:34:32,190:INFO:Ridge Regression Imported successfully
2024-09-16 19:34:32,190:INFO:Starting cross validation
2024-09-16 19:34:32,194:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:34:32,923:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.1653e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 19:34:32,927:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.31329e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 19:34:32,966:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.16211e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 19:34:33,654:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.16155e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 19:34:33,708:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.15281e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 19:34:33,708:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.14216e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 19:34:33,716:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.1704e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 19:34:34,211:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.16082e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 19:34:34,223:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.16172e-18): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-09-16 19:34:34,320:INFO:Calculating mean and std
2024-09-16 19:34:34,321:INFO:Creating metrics dataframe
2024-09-16 19:34:34,323:INFO:Uploading results into container
2024-09-16 19:34:34,324:INFO:Uploading model into container now
2024-09-16 19:34:34,325:INFO:_master_model_container: 3
2024-09-16 19:34:34,325:INFO:_display_container: 2
2024-09-16 19:34:34,325:INFO:Ridge(random_state=123)
2024-09-16 19:34:34,325:INFO:create_model() successfully completed......................................
2024-09-16 19:34:34,407:INFO:SubProcess create_model() end ==================================
2024-09-16 19:34:34,407:INFO:Creating metrics dataframe
2024-09-16 19:34:34,410:INFO:Initializing Elastic Net
2024-09-16 19:34:34,411:INFO:Total runtime is 0.3657550454139709 minutes
2024-09-16 19:34:34,411:INFO:SubProcess create_model() called ==================================
2024-09-16 19:34:34,411:INFO:Initializing create_model()
2024-09-16 19:34:34,411:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016C7A30E250>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016C0AEABB90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:34:34,411:INFO:Checking exceptions
2024-09-16 19:34:34,411:INFO:Importing libraries
2024-09-16 19:34:34,411:INFO:Copying training dataset
2024-09-16 19:34:34,418:INFO:Defining folds
2024-09-16 19:34:34,418:INFO:Declaring metric variables
2024-09-16 19:34:34,418:INFO:Importing untrained model
2024-09-16 19:34:34,419:INFO:Elastic Net Imported successfully
2024-09-16 19:34:34,419:INFO:Starting cross validation
2024-09-16 19:34:34,423:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:34:36,701:INFO:Calculating mean and std
2024-09-16 19:34:36,702:INFO:Creating metrics dataframe
2024-09-16 19:34:36,704:INFO:Uploading results into container
2024-09-16 19:34:36,705:INFO:Uploading model into container now
2024-09-16 19:34:36,705:INFO:_master_model_container: 4
2024-09-16 19:34:36,706:INFO:_display_container: 2
2024-09-16 19:34:36,706:INFO:ElasticNet(random_state=123)
2024-09-16 19:34:36,706:INFO:create_model() successfully completed......................................
2024-09-16 19:34:36,788:INFO:SubProcess create_model() end ==================================
2024-09-16 19:34:36,788:INFO:Creating metrics dataframe
2024-09-16 19:34:36,791:INFO:Initializing Least Angle Regression
2024-09-16 19:34:36,792:INFO:Total runtime is 0.4054482817649841 minutes
2024-09-16 19:34:36,792:INFO:SubProcess create_model() called ==================================
2024-09-16 19:34:36,792:INFO:Initializing create_model()
2024-09-16 19:34:36,792:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016C7A30E250>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016C0AEABB90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:34:36,792:INFO:Checking exceptions
2024-09-16 19:34:36,792:INFO:Importing libraries
2024-09-16 19:34:36,792:INFO:Copying training dataset
2024-09-16 19:34:36,799:INFO:Defining folds
2024-09-16 19:34:36,799:INFO:Declaring metric variables
2024-09-16 19:34:36,800:INFO:Importing untrained model
2024-09-16 19:34:36,800:INFO:Least Angle Regression Imported successfully
2024-09-16 19:34:36,800:INFO:Starting cross validation
2024-09-16 19:34:36,804:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:34:37,432:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=7.507e+02, with an active set of 51 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,436:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=7.398e+02, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,437:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=6.903e+02, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,440:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=6.115e+02, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,447:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=6.766e+02, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,449:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=5.678e+03, with an active set of 77 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,449:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=5.551e+03, with an active set of 78 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,453:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=7.454e+02, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,455:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=1.119e+03, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,458:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=5.117e+02, with an active set of 48 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,462:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=4.506e+02, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,465:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=7.938e+02, with an active set of 60 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,466:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 82 iterations, i.e. alpha=5.650e+02, with an active set of 69 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,466:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=7.735e+02, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,468:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=4.405e+04, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,470:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=2.817e+04, with an active set of 91 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,472:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 112 iterations, i.e. alpha=4.569e+04, with an active set of 93 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,473:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=8.438e+02, with an active set of 81 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,474:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=6.889e+02, with an active set of 81 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,475:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=6.362e+02, with an active set of 83 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,476:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=5.884e+02, with an active set of 84 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,477:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=4.347e+02, with an active set of 85 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,478:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=3.550e+02, with an active set of 85 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,479:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=2.184e+02, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,479:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=1.207e+02, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,480:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=4.657e+01, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,481:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=2.065e+01, with an active set of 87 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,482:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=2.705e+03, with an active set of 91 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,483:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=1.377e+01, with an active set of 89 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,483:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=9.817e+00, with an active set of 89 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,483:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=1.709e+03, with an active set of 93 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,484:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=1.009e+03, with an active set of 93 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,484:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=6.965e+00, with an active set of 90 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,485:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=6.700e+00, with an active set of 90 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:37,485:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=2.479e+00, with an active set of 90 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:38,257:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=5.990e+02, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:38,260:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=9.455e+02, with an active set of 44 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:38,276:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=9.048e+02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:38,280:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.101e+03, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:38,291:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=1.805e+09, with an active set of 86 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:38,294:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=1.419e+09, with an active set of 91 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:38,295:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=4.235e+08, with an active set of 93 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:38,876:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=7.038e+03, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:39,114:INFO:Calculating mean and std
2024-09-16 19:34:39,116:INFO:Creating metrics dataframe
2024-09-16 19:34:39,119:INFO:Uploading results into container
2024-09-16 19:34:39,120:INFO:Uploading model into container now
2024-09-16 19:34:39,121:INFO:_master_model_container: 5
2024-09-16 19:34:39,122:INFO:_display_container: 2
2024-09-16 19:34:39,122:INFO:Lars(random_state=123)
2024-09-16 19:34:39,122:INFO:create_model() successfully completed......................................
2024-09-16 19:34:39,230:INFO:SubProcess create_model() end ==================================
2024-09-16 19:34:39,230:INFO:Creating metrics dataframe
2024-09-16 19:34:39,235:INFO:Initializing Lasso Least Angle Regression
2024-09-16 19:34:39,235:INFO:Total runtime is 0.4461629311243693 minutes
2024-09-16 19:34:39,235:INFO:SubProcess create_model() called ==================================
2024-09-16 19:34:39,236:INFO:Initializing create_model()
2024-09-16 19:34:39,236:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016C7A30E250>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016C0AEABB90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:34:39,236:INFO:Checking exceptions
2024-09-16 19:34:39,236:INFO:Importing libraries
2024-09-16 19:34:39,236:INFO:Copying training dataset
2024-09-16 19:34:39,248:INFO:Defining folds
2024-09-16 19:34:39,248:INFO:Declaring metric variables
2024-09-16 19:34:39,248:INFO:Importing untrained model
2024-09-16 19:34:39,249:INFO:Lasso Least Angle Regression Imported successfully
2024-09-16 19:34:39,249:INFO:Starting cross validation
2024-09-16 19:34:39,253:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:34:39,862:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=1.435e+02, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:39,864:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=1.180e+02, with an active set of 60 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:39,871:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 82 iterations, alpha=9.372e+01, previous alpha=7.755e+01, with an active set of 73 regressors.
  warnings.warn(

2024-09-16 19:34:39,874:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=3.070e+01, with an active set of 75 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:39,882:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 98 iterations, alpha=1.535e+01, previous alpha=1.535e+01, with an active set of 81 regressors.
  warnings.warn(

2024-09-16 19:34:39,957:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 108 iterations, alpha=2.212e+00, previous alpha=2.212e+00, with an active set of 81 regressors.
  warnings.warn(

2024-09-16 19:34:40,698:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=1.548e+01, with an active set of 76 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:40,699:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=1.044e+01, with an active set of 77 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:40,716:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 108 iterations, alpha=5.444e+00, previous alpha=5.444e+00, with an active set of 79 regressors.
  warnings.warn(

2024-09-16 19:34:40,727:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 102 iterations, alpha=9.960e+00, previous alpha=5.387e+00, with an active set of 79 regressors.
  warnings.warn(

2024-09-16 19:34:40,771:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=2.452e+01, with an active set of 75 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:40,781:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 101 iterations, alpha=1.817e+01, previous alpha=1.817e+01, with an active set of 76 regressors.
  warnings.warn(

2024-09-16 19:34:41,412:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=2.071e+02, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:41,414:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=1.952e+02, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:41,417:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=1.306e+02, with an active set of 61 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-09-16 19:34:41,419:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 68 iterations, alpha=1.363e+02, previous alpha=1.306e+02, with an active set of 61 regressors.
  warnings.warn(

2024-09-16 19:34:41,461:WARNING:D:\grad-proj\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 99 iterations, alpha=2.537e+01, previous alpha=2.533e+01, with an active set of 78 regressors.
  warnings.warn(

2024-09-16 19:34:41,547:INFO:Calculating mean and std
2024-09-16 19:34:41,548:INFO:Creating metrics dataframe
2024-09-16 19:34:41,550:INFO:Uploading results into container
2024-09-16 19:34:41,551:INFO:Uploading model into container now
2024-09-16 19:34:41,551:INFO:_master_model_container: 6
2024-09-16 19:34:41,551:INFO:_display_container: 2
2024-09-16 19:34:41,552:INFO:LassoLars(random_state=123)
2024-09-16 19:34:41,552:INFO:create_model() successfully completed......................................
2024-09-16 19:34:41,641:INFO:SubProcess create_model() end ==================================
2024-09-16 19:34:41,641:INFO:Creating metrics dataframe
2024-09-16 19:34:41,644:INFO:Initializing Orthogonal Matching Pursuit
2024-09-16 19:34:41,645:INFO:Total runtime is 0.48632070620854695 minutes
2024-09-16 19:34:41,645:INFO:SubProcess create_model() called ==================================
2024-09-16 19:34:41,645:INFO:Initializing create_model()
2024-09-16 19:34:41,645:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016C7A30E250>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016C0AEABB90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:34:41,645:INFO:Checking exceptions
2024-09-16 19:34:41,645:INFO:Importing libraries
2024-09-16 19:34:41,645:INFO:Copying training dataset
2024-09-16 19:34:41,653:INFO:Defining folds
2024-09-16 19:34:41,653:INFO:Declaring metric variables
2024-09-16 19:34:41,653:INFO:Importing untrained model
2024-09-16 19:34:41,653:INFO:Orthogonal Matching Pursuit Imported successfully
2024-09-16 19:34:41,654:INFO:Starting cross validation
2024-09-16 19:34:41,657:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:34:43,843:INFO:Calculating mean and std
2024-09-16 19:34:43,844:INFO:Creating metrics dataframe
2024-09-16 19:34:43,846:INFO:Uploading results into container
2024-09-16 19:34:43,847:INFO:Uploading model into container now
2024-09-16 19:34:43,847:INFO:_master_model_container: 7
2024-09-16 19:34:43,847:INFO:_display_container: 2
2024-09-16 19:34:43,848:INFO:OrthogonalMatchingPursuit()
2024-09-16 19:34:43,848:INFO:create_model() successfully completed......................................
2024-09-16 19:34:43,929:INFO:SubProcess create_model() end ==================================
2024-09-16 19:34:43,930:INFO:Creating metrics dataframe
2024-09-16 19:34:43,933:INFO:Initializing Bayesian Ridge
2024-09-16 19:34:43,933:INFO:Total runtime is 0.5244582732518513 minutes
2024-09-16 19:34:43,933:INFO:SubProcess create_model() called ==================================
2024-09-16 19:34:43,933:INFO:Initializing create_model()
2024-09-16 19:34:43,933:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016C7A30E250>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016C0AEABB90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:34:43,933:INFO:Checking exceptions
2024-09-16 19:34:43,934:INFO:Importing libraries
2024-09-16 19:34:43,934:INFO:Copying training dataset
2024-09-16 19:34:43,940:INFO:Defining folds
2024-09-16 19:34:43,941:INFO:Declaring metric variables
2024-09-16 19:34:43,941:INFO:Importing untrained model
2024-09-16 19:34:43,941:INFO:Bayesian Ridge Imported successfully
2024-09-16 19:34:43,941:INFO:Starting cross validation
2024-09-16 19:34:43,945:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:34:46,766:INFO:Calculating mean and std
2024-09-16 19:34:46,767:INFO:Creating metrics dataframe
2024-09-16 19:34:46,769:INFO:Uploading results into container
2024-09-16 19:34:46,770:INFO:Uploading model into container now
2024-09-16 19:34:46,770:INFO:_master_model_container: 8
2024-09-16 19:34:46,770:INFO:_display_container: 2
2024-09-16 19:34:46,771:INFO:BayesianRidge()
2024-09-16 19:34:46,771:INFO:create_model() successfully completed......................................
2024-09-16 19:34:46,853:INFO:SubProcess create_model() end ==================================
2024-09-16 19:34:46,854:INFO:Creating metrics dataframe
2024-09-16 19:34:46,857:INFO:Initializing Passive Aggressive Regressor
2024-09-16 19:34:46,857:INFO:Total runtime is 0.5731943607330322 minutes
2024-09-16 19:34:46,857:INFO:SubProcess create_model() called ==================================
2024-09-16 19:34:46,857:INFO:Initializing create_model()
2024-09-16 19:34:46,857:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016C7A30E250>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016C0AEABB90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:34:46,857:INFO:Checking exceptions
2024-09-16 19:34:46,858:INFO:Importing libraries
2024-09-16 19:34:46,858:INFO:Copying training dataset
2024-09-16 19:34:46,864:INFO:Defining folds
2024-09-16 19:34:46,864:INFO:Declaring metric variables
2024-09-16 19:34:46,865:INFO:Importing untrained model
2024-09-16 19:34:46,865:INFO:Passive Aggressive Regressor Imported successfully
2024-09-16 19:34:46,865:INFO:Starting cross validation
2024-09-16 19:34:46,869:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:34:49,108:INFO:Calculating mean and std
2024-09-16 19:34:49,109:INFO:Creating metrics dataframe
2024-09-16 19:34:49,111:INFO:Uploading results into container
2024-09-16 19:34:49,112:INFO:Uploading model into container now
2024-09-16 19:34:49,112:INFO:_master_model_container: 9
2024-09-16 19:34:49,112:INFO:_display_container: 2
2024-09-16 19:34:49,113:INFO:PassiveAggressiveRegressor(random_state=123)
2024-09-16 19:34:49,113:INFO:create_model() successfully completed......................................
2024-09-16 19:34:49,194:INFO:SubProcess create_model() end ==================================
2024-09-16 19:34:49,195:INFO:Creating metrics dataframe
2024-09-16 19:34:49,198:INFO:Initializing Huber Regressor
2024-09-16 19:34:49,198:INFO:Total runtime is 0.6122010310490926 minutes
2024-09-16 19:34:49,199:INFO:SubProcess create_model() called ==================================
2024-09-16 19:34:49,199:INFO:Initializing create_model()
2024-09-16 19:34:49,199:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016C7A30E250>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016C0AEABB90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:34:49,199:INFO:Checking exceptions
2024-09-16 19:34:49,199:INFO:Importing libraries
2024-09-16 19:34:49,199:INFO:Copying training dataset
2024-09-16 19:34:49,206:INFO:Defining folds
2024-09-16 19:34:49,206:INFO:Declaring metric variables
2024-09-16 19:34:49,206:INFO:Importing untrained model
2024-09-16 19:34:49,207:INFO:Huber Regressor Imported successfully
2024-09-16 19:34:49,207:INFO:Starting cross validation
2024-09-16 19:34:49,210:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:34:52,419:INFO:Calculating mean and std
2024-09-16 19:34:52,420:INFO:Creating metrics dataframe
2024-09-16 19:34:52,422:INFO:Uploading results into container
2024-09-16 19:34:52,423:INFO:Uploading model into container now
2024-09-16 19:34:52,423:INFO:_master_model_container: 10
2024-09-16 19:34:52,424:INFO:_display_container: 2
2024-09-16 19:34:52,424:INFO:HuberRegressor()
2024-09-16 19:34:52,424:INFO:create_model() successfully completed......................................
2024-09-16 19:34:52,507:INFO:SubProcess create_model() end ==================================
2024-09-16 19:34:52,507:INFO:Creating metrics dataframe
2024-09-16 19:34:52,510:INFO:Initializing K Neighbors Regressor
2024-09-16 19:34:52,510:INFO:Total runtime is 0.6674094597498575 minutes
2024-09-16 19:34:52,510:INFO:SubProcess create_model() called ==================================
2024-09-16 19:34:52,511:INFO:Initializing create_model()
2024-09-16 19:34:52,511:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016C7A30E250>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016C0AEABB90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:34:52,511:INFO:Checking exceptions
2024-09-16 19:34:52,511:INFO:Importing libraries
2024-09-16 19:34:52,511:INFO:Copying training dataset
2024-09-16 19:34:52,518:INFO:Defining folds
2024-09-16 19:34:52,518:INFO:Declaring metric variables
2024-09-16 19:34:52,518:INFO:Importing untrained model
2024-09-16 19:34:52,519:INFO:K Neighbors Regressor Imported successfully
2024-09-16 19:34:52,519:INFO:Starting cross validation
2024-09-16 19:34:52,523:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:34:55,209:INFO:Calculating mean and std
2024-09-16 19:34:55,210:INFO:Creating metrics dataframe
2024-09-16 19:34:55,212:INFO:Uploading results into container
2024-09-16 19:34:55,213:INFO:Uploading model into container now
2024-09-16 19:34:55,213:INFO:_master_model_container: 11
2024-09-16 19:34:55,213:INFO:_display_container: 2
2024-09-16 19:34:55,214:INFO:KNeighborsRegressor(n_jobs=-1)
2024-09-16 19:34:55,214:INFO:create_model() successfully completed......................................
2024-09-16 19:34:55,299:INFO:SubProcess create_model() end ==================================
2024-09-16 19:34:55,300:INFO:Creating metrics dataframe
2024-09-16 19:34:55,303:INFO:Initializing Decision Tree Regressor
2024-09-16 19:34:55,303:INFO:Total runtime is 0.7139529506365457 minutes
2024-09-16 19:34:55,303:INFO:SubProcess create_model() called ==================================
2024-09-16 19:34:55,303:INFO:Initializing create_model()
2024-09-16 19:34:55,303:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016C7A30E250>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016C0AEABB90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:34:55,304:INFO:Checking exceptions
2024-09-16 19:34:55,304:INFO:Importing libraries
2024-09-16 19:34:55,304:INFO:Copying training dataset
2024-09-16 19:34:55,311:INFO:Defining folds
2024-09-16 19:34:55,311:INFO:Declaring metric variables
2024-09-16 19:34:55,312:INFO:Importing untrained model
2024-09-16 19:34:55,312:INFO:Decision Tree Regressor Imported successfully
2024-09-16 19:34:55,312:INFO:Starting cross validation
2024-09-16 19:34:55,316:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:34:57,855:INFO:Calculating mean and std
2024-09-16 19:34:57,856:INFO:Creating metrics dataframe
2024-09-16 19:34:57,858:INFO:Uploading results into container
2024-09-16 19:34:57,859:INFO:Uploading model into container now
2024-09-16 19:34:57,859:INFO:_master_model_container: 12
2024-09-16 19:34:57,859:INFO:_display_container: 2
2024-09-16 19:34:57,860:INFO:DecisionTreeRegressor(random_state=123)
2024-09-16 19:34:57,860:INFO:create_model() successfully completed......................................
2024-09-16 19:34:57,942:INFO:SubProcess create_model() end ==================================
2024-09-16 19:34:57,942:INFO:Creating metrics dataframe
2024-09-16 19:34:57,945:INFO:Initializing Random Forest Regressor
2024-09-16 19:34:57,945:INFO:Total runtime is 0.7579894264539082 minutes
2024-09-16 19:34:57,946:INFO:SubProcess create_model() called ==================================
2024-09-16 19:34:57,946:INFO:Initializing create_model()
2024-09-16 19:34:57,946:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016C7A30E250>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016C0AEABB90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:34:57,946:INFO:Checking exceptions
2024-09-16 19:34:57,946:INFO:Importing libraries
2024-09-16 19:34:57,946:INFO:Copying training dataset
2024-09-16 19:34:57,953:INFO:Defining folds
2024-09-16 19:34:57,953:INFO:Declaring metric variables
2024-09-16 19:34:57,954:INFO:Importing untrained model
2024-09-16 19:34:57,954:INFO:Random Forest Regressor Imported successfully
2024-09-16 19:34:57,954:INFO:Starting cross validation
2024-09-16 19:34:57,958:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:35:30,241:INFO:Calculating mean and std
2024-09-16 19:35:30,242:INFO:Creating metrics dataframe
2024-09-16 19:35:30,244:INFO:Uploading results into container
2024-09-16 19:35:30,245:INFO:Uploading model into container now
2024-09-16 19:35:30,246:INFO:_master_model_container: 13
2024-09-16 19:35:30,246:INFO:_display_container: 2
2024-09-16 19:35:30,247:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-09-16 19:35:30,247:INFO:create_model() successfully completed......................................
2024-09-16 19:35:30,352:INFO:SubProcess create_model() end ==================================
2024-09-16 19:35:30,353:INFO:Creating metrics dataframe
2024-09-16 19:35:30,358:INFO:Initializing Extra Trees Regressor
2024-09-16 19:35:30,358:INFO:Total runtime is 1.2982072512308755 minutes
2024-09-16 19:35:30,358:INFO:SubProcess create_model() called ==================================
2024-09-16 19:35:30,359:INFO:Initializing create_model()
2024-09-16 19:35:30,359:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016C7A30E250>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016C0AEABB90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:35:30,359:INFO:Checking exceptions
2024-09-16 19:35:30,359:INFO:Importing libraries
2024-09-16 19:35:30,359:INFO:Copying training dataset
2024-09-16 19:35:30,372:INFO:Defining folds
2024-09-16 19:35:30,372:INFO:Declaring metric variables
2024-09-16 19:35:30,373:INFO:Importing untrained model
2024-09-16 19:35:30,374:INFO:Extra Trees Regressor Imported successfully
2024-09-16 19:35:30,374:INFO:Starting cross validation
2024-09-16 19:35:30,380:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:36:02,398:INFO:Calculating mean and std
2024-09-16 19:36:02,400:INFO:Creating metrics dataframe
2024-09-16 19:36:02,403:INFO:Uploading results into container
2024-09-16 19:36:02,404:INFO:Uploading model into container now
2024-09-16 19:36:02,405:INFO:_master_model_container: 14
2024-09-16 19:36:02,405:INFO:_display_container: 2
2024-09-16 19:36:02,405:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-09-16 19:36:02,406:INFO:create_model() successfully completed......................................
2024-09-16 19:36:02,517:INFO:SubProcess create_model() end ==================================
2024-09-16 19:36:02,517:INFO:Creating metrics dataframe
2024-09-16 19:36:02,522:INFO:Initializing AdaBoost Regressor
2024-09-16 19:36:02,523:INFO:Total runtime is 1.8342911084493 minutes
2024-09-16 19:36:02,523:INFO:SubProcess create_model() called ==================================
2024-09-16 19:36:02,523:INFO:Initializing create_model()
2024-09-16 19:36:02,523:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016C7A30E250>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016C0AEABB90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:36:02,524:INFO:Checking exceptions
2024-09-16 19:36:02,524:INFO:Importing libraries
2024-09-16 19:36:02,524:INFO:Copying training dataset
2024-09-16 19:36:02,536:INFO:Defining folds
2024-09-16 19:36:02,536:INFO:Declaring metric variables
2024-09-16 19:36:02,536:INFO:Importing untrained model
2024-09-16 19:36:02,537:INFO:AdaBoost Regressor Imported successfully
2024-09-16 19:36:02,538:INFO:Starting cross validation
2024-09-16 19:36:02,547:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:36:10,436:INFO:Calculating mean and std
2024-09-16 19:36:10,437:INFO:Creating metrics dataframe
2024-09-16 19:36:10,439:INFO:Uploading results into container
2024-09-16 19:36:10,440:INFO:Uploading model into container now
2024-09-16 19:36:10,441:INFO:_master_model_container: 15
2024-09-16 19:36:10,441:INFO:_display_container: 2
2024-09-16 19:36:10,442:INFO:AdaBoostRegressor(random_state=123)
2024-09-16 19:36:10,442:INFO:create_model() successfully completed......................................
2024-09-16 19:36:10,536:INFO:SubProcess create_model() end ==================================
2024-09-16 19:36:10,536:INFO:Creating metrics dataframe
2024-09-16 19:36:10,541:INFO:Initializing Gradient Boosting Regressor
2024-09-16 19:36:10,541:INFO:Total runtime is 1.9679222742716471 minutes
2024-09-16 19:36:10,541:INFO:SubProcess create_model() called ==================================
2024-09-16 19:36:10,542:INFO:Initializing create_model()
2024-09-16 19:36:10,542:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016C7A30E250>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016C0AEABB90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:36:10,542:INFO:Checking exceptions
2024-09-16 19:36:10,542:INFO:Importing libraries
2024-09-16 19:36:10,542:INFO:Copying training dataset
2024-09-16 19:36:10,554:INFO:Defining folds
2024-09-16 19:36:10,554:INFO:Declaring metric variables
2024-09-16 19:36:10,555:INFO:Importing untrained model
2024-09-16 19:36:10,555:INFO:Gradient Boosting Regressor Imported successfully
2024-09-16 19:36:10,556:INFO:Starting cross validation
2024-09-16 19:36:10,563:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:36:19,546:INFO:Calculating mean and std
2024-09-16 19:36:19,547:INFO:Creating metrics dataframe
2024-09-16 19:36:19,549:INFO:Uploading results into container
2024-09-16 19:36:19,550:INFO:Uploading model into container now
2024-09-16 19:36:19,551:INFO:_master_model_container: 16
2024-09-16 19:36:19,551:INFO:_display_container: 2
2024-09-16 19:36:19,551:INFO:GradientBoostingRegressor(random_state=123)
2024-09-16 19:36:19,551:INFO:create_model() successfully completed......................................
2024-09-16 19:36:19,633:INFO:SubProcess create_model() end ==================================
2024-09-16 19:36:19,633:INFO:Creating metrics dataframe
2024-09-16 19:36:19,636:INFO:Initializing Light Gradient Boosting Machine
2024-09-16 19:36:19,636:INFO:Total runtime is 2.1195014238357546 minutes
2024-09-16 19:36:19,636:INFO:SubProcess create_model() called ==================================
2024-09-16 19:36:19,636:INFO:Initializing create_model()
2024-09-16 19:36:19,637:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016C7A30E250>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016C0AEABB90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:36:19,637:INFO:Checking exceptions
2024-09-16 19:36:19,637:INFO:Importing libraries
2024-09-16 19:36:19,637:INFO:Copying training dataset
2024-09-16 19:36:19,644:INFO:Defining folds
2024-09-16 19:36:19,644:INFO:Declaring metric variables
2024-09-16 19:36:19,644:INFO:Importing untrained model
2024-09-16 19:36:19,645:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-16 19:36:19,645:INFO:Starting cross validation
2024-09-16 19:36:19,648:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:36:23,223:INFO:Calculating mean and std
2024-09-16 19:36:23,225:INFO:Creating metrics dataframe
2024-09-16 19:36:23,227:INFO:Uploading results into container
2024-09-16 19:36:23,229:INFO:Uploading model into container now
2024-09-16 19:36:23,229:INFO:_master_model_container: 17
2024-09-16 19:36:23,229:INFO:_display_container: 2
2024-09-16 19:36:23,230:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-09-16 19:36:23,230:INFO:create_model() successfully completed......................................
2024-09-16 19:36:23,340:INFO:SubProcess create_model() end ==================================
2024-09-16 19:36:23,341:INFO:Creating metrics dataframe
2024-09-16 19:36:23,344:INFO:Initializing Dummy Regressor
2024-09-16 19:36:23,344:INFO:Total runtime is 2.1812994400660197 minutes
2024-09-16 19:36:23,344:INFO:SubProcess create_model() called ==================================
2024-09-16 19:36:23,344:INFO:Initializing create_model()
2024-09-16 19:36:23,344:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016C7A30E250>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016C0AEABB90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:36:23,345:INFO:Checking exceptions
2024-09-16 19:36:23,345:INFO:Importing libraries
2024-09-16 19:36:23,345:INFO:Copying training dataset
2024-09-16 19:36:23,352:INFO:Defining folds
2024-09-16 19:36:23,352:INFO:Declaring metric variables
2024-09-16 19:36:23,353:INFO:Importing untrained model
2024-09-16 19:36:23,353:INFO:Dummy Regressor Imported successfully
2024-09-16 19:36:23,353:INFO:Starting cross validation
2024-09-16 19:36:23,357:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-16 19:36:25,363:INFO:Calculating mean and std
2024-09-16 19:36:25,364:INFO:Creating metrics dataframe
2024-09-16 19:36:25,366:INFO:Uploading results into container
2024-09-16 19:36:25,367:INFO:Uploading model into container now
2024-09-16 19:36:25,367:INFO:_master_model_container: 18
2024-09-16 19:36:25,368:INFO:_display_container: 2
2024-09-16 19:36:25,368:INFO:DummyRegressor()
2024-09-16 19:36:25,368:INFO:create_model() successfully completed......................................
2024-09-16 19:36:25,449:INFO:SubProcess create_model() end ==================================
2024-09-16 19:36:25,449:INFO:Creating metrics dataframe
2024-09-16 19:36:25,454:WARNING:D:\grad-proj\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-09-16 19:36:25,456:INFO:Initializing create_model()
2024-09-16 19:36:25,456:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016C7A30E250>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-16 19:36:25,456:INFO:Checking exceptions
2024-09-16 19:36:25,457:INFO:Importing libraries
2024-09-16 19:36:25,457:INFO:Copying training dataset
2024-09-16 19:36:25,464:INFO:Defining folds
2024-09-16 19:36:25,464:INFO:Declaring metric variables
2024-09-16 19:36:25,464:INFO:Importing untrained model
2024-09-16 19:36:25,464:INFO:Declaring custom model
2024-09-16 19:36:25,465:INFO:Random Forest Regressor Imported successfully
2024-09-16 19:36:25,469:INFO:Cross validation set to False
2024-09-16 19:36:25,469:INFO:Fitting Model
2024-09-16 19:36:29,173:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-09-16 19:36:29,173:INFO:create_model() successfully completed......................................
2024-09-16 19:36:29,275:INFO:_master_model_container: 18
2024-09-16 19:36:29,276:INFO:_display_container: 2
2024-09-16 19:36:29,276:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-09-16 19:36:29,276:INFO:compare_models() successfully completed......................................
2024-09-16 19:36:29,292:INFO:Initializing save_model()
2024-09-16 19:36:29,292:INFO:save_model(model=RandomForestRegressor(n_jobs=-1, random_state=123), model_name=D:\Grad-proj\ML\saved model\my-model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Dell\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['long', 'lat', 'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['city', 'neighborhood',
                                             'subcategory', 'facade',
                                             'payment_method', 'bedrooms',
                                             'bathrooms', 'furnished', 'floor',
                                             'building_...
                                             'bathrooms', 'furnished', 'floor',
                                             'building_age'],
                                    transformer=OneHotEncoder(cols=['city',
                                                                    'subcategory',
                                                                    'facade',
                                                                    'payment_method',
                                                                    'bedrooms',
                                                                    'bathrooms',
                                                                    'furnished',
                                                                    'floor',
                                                                    'building_age'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['neighborhood'],
                                    transformer=TargetEncoder(cols=['neighborhood'],
                                                              handle_missing='return_nan')))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2024-09-16 19:36:29,292:INFO:Adding model into prep_pipe
2024-09-16 19:36:29,401:INFO:D:\Grad-proj\ML\saved model\my-model.pkl saved in current working directory
2024-09-16 19:36:29,415:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['long', 'lat', 'area'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['city', 'neighborhood',
                                             'subcategory', 'facade',
                                             'payment_method', 'bedrooms',
                                             'bathrooms', 'furnished', 'floor',
                                             'building_age'],
                                    transformer=SimpleImputer(strateg...
                                                                    'subcategory',
                                                                    'facade',
                                                                    'payment_method',
                                                                    'bedrooms',
                                                                    'bathrooms',
                                                                    'furnished',
                                                                    'floor',
                                                                    'building_age'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['neighborhood'],
                                    transformer=TargetEncoder(cols=['neighborhood'],
                                                              handle_missing='return_nan'))),
                ('trained_model',
                 RandomForestRegressor(n_jobs=-1, random_state=123))])
2024-09-16 19:36:29,415:INFO:save_model() successfully completed......................................
2024-09-16 19:36:29,499:INFO:Initializing load_model()
2024-09-16 19:36:29,499:INFO:load_model(model_name=D:/Grad-proj/ML/saved model/my-model, platform=None, authentication=None, verbose=True)
